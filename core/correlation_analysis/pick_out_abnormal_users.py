import os
import pandas as pd
import numpy as np
from datetime import datetime

def normalize_id(id_value):
    """è§„èŒƒåŒ–ç”¨æˆ·IDï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´"""
    try:
        id_str = str(id_value).strip()
        if id_str == '-2147483648':
            return id_str
        return str(int(float(id_str)))
    except:
        return str(id_value).strip()

def ensure_dir(directory):
    """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if not os.path.exists(directory):
        os.makedirs(directory)

class AdvancedAnomalyDetector:
    """é«˜çº§å¼‚å¸¸ç”¨æˆ·æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.merged_df = None
        self.edges_df = None
        self.popularity_map = {}
        self.user_neighbors = {}  # å­˜å‚¨æ¯ä¸ªç”¨æˆ·çš„é‚»å±…
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        
        # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„æ•°æ®è·¯å¾„ï¼Œå…¼å®¹create3.pyçš„è¾“å‡º
        merged_data_path = 'C:/Tengfei/data/results/user_3855570307_metrics/merged_metrics_popularity.csv'
        if not os.path.exists(merged_data_path):
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ {merged_data_path}")
            return False
        
        self.merged_df = pd.read_csv(merged_data_path)
        self.merged_df['user_id'] = self.merged_df['user_id'].apply(normalize_id)
        
        # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„è¾¹æ•°æ®è·¯å¾„
        edges_path = 'C:/Tengfei/data/data/domain_network3/user_3855570307/edges.csv'
        if not os.path.exists(edges_path):
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ {edges_path}")
            return False
            
        self.edges_df = pd.read_csv(edges_path)
        self.edges_df['source'] = self.edges_df['source'].apply(normalize_id)
        self.edges_df['target'] = self.edges_df['target'].apply(normalize_id)
        
        # åˆ›å»ºæµè¡Œåº¦æ˜ å°„
        self.popularity_map = dict(zip(self.merged_df['user_id'], self.merged_df['avg_popularity']))
        
        # é¢„å¤„ç†é‚»å±…å…³ç³»ï¼ˆç”¨äºæ–¹æ¡ˆä¸‰ï¼‰
        print("æ­£åœ¨é¢„å¤„ç†é‚»å±…å…³ç³»...")
        self.user_neighbors = {}
        for _, row in self.edges_df.iterrows():
            source = row['source']
            target = row['target']
            if source not in self.user_neighbors:
                self.user_neighbors[source] = set()
            self.user_neighbors[source].add(target)
        
        print(f"æ•°æ®åŠ è½½å®Œæˆ: {len(self.merged_df)} ä¸ªå¯åˆ†æç”¨æˆ·")
        
        # ğŸ”¥ æ–°å¢ï¼šæ£€æŸ¥æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†åˆ—æ˜¯å¦å­˜åœ¨
        if 'is_celebrity' in self.merged_df.columns:
            celebrity_count = self.merged_df['is_celebrity'].sum()
            print(f"âœ… æ£€æµ‹åˆ°æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†åˆ—ï¼Œå…±æœ‰ {celebrity_count} ä¸ªæ˜æ˜Ÿç”¨æˆ·")
        else:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†åˆ—ï¼Œæ–¹æ³•4å°†æ— æ³•ä½¿ç”¨")
        
        return True
    
    def method1_influence_edge_ratio(self, exclude_pct):
        """æ–¹æ³•1: å½±å“åŠ›/è¿è¾¹æ•°æ¯”å€¼å¼‚å¸¸æ£€æµ‹"""
        print(f"\n=== æ–¹æ³•1: å½±å“åŠ›/è¿è¾¹æ•°æ¯”å€¼æ£€æµ‹ (æ’é™¤å‰{exclude_pct}%) ===")
        
        # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„è¿è¾¹æ•°
        user_out_edges = self.edges_df['source'].value_counts().to_dict()
        user_in_edges = self.edges_df['target'].value_counts().to_dict()
        
        result_data = []
        for _, row in self.merged_df.iterrows():
            user_id = row['user_id']
            avg_popularity = row['avg_popularity']
            
            out_count = user_out_edges.get(user_id, 0)
            in_count = user_in_edges.get(user_id, 0)
            total_edges = out_count + in_count
            
            influence_edge_ratio = avg_popularity / (total_edges + 1e-10)
            
            result_data.append({
                'user_id': user_id,
                'avg_popularity': avg_popularity,
                'edge_count': total_edges,
                'influence_edge_ratio': influence_edge_ratio
            })
        
        result_df = pd.DataFrame(result_data)
        result_df = result_df.sort_values('influence_edge_ratio', ascending=False)
        
        if exclude_pct == 0:
            abnormal_users = set()
        else:
            n_to_exclude = int(np.ceil(len(result_df) * exclude_pct / 100))
            abnormal_users = set(result_df.head(n_to_exclude)['user_id'])
        
        print(f"æ£€æµ‹åˆ° {len(abnormal_users)} ä¸ªæ¯”å€¼å¼‚å¸¸ç”¨æˆ·")
        return abnormal_users
    
    def method2_structural_hole_anomaly(self, exclude_pct):
        """æ–¹æ³•2: ç»“æ„æ´å¼‚å¸¸æ£€æµ‹ - ç›´æ¥ä½¿ç”¨CSVä¸­çš„æ•°æ®"""
        print(f"\n=== æ–¹æ³•2: ç»“æ„æ´å¼‚å¸¸æ£€æµ‹ (æ’é™¤å‰{exclude_pct}%) ===")
        
        if exclude_pct == 0:
            print("åŸå§‹ç½‘ç»œï¼Œæ— éœ€æ£€æµ‹å¼‚å¸¸ç”¨æˆ·")
            return set()
        
        # ğŸ”¥ ä¿®æ”¹ï¼šæ£€æŸ¥ä»‹æ•°ä¸­å¿ƒæ€§åˆ—æ˜¯å¦å­˜åœ¨
        if 'betweenness_centrality' not in self.merged_df.columns:
            print("âŒ æ•°æ®ä¸­ç¼ºå°‘betweenness_centralityåˆ—ï¼Œæ–¹æ³•2æ— æ³•ä½¿ç”¨")
            return set()
        
        print("æ­£åœ¨è®¡ç®—ç»“æ„æ´å¼‚å¸¸åˆ†æ•°...")
        
        # ç›´æ¥ä»CSVä¸­è·å–æ•°æ®ï¼Œæ— éœ€é‡æ–°è®¡ç®—
        anomaly_scores = []
        max_popularity = self.merged_df['avg_popularity'].max()
        
        for _, row in self.merged_df.iterrows():
            user_id = row['user_id']
            popularity = row['avg_popularity']
            betweenness = row['betweenness_centrality']
            
            # è®¡ç®—å¼‚å¸¸åˆ†æ•°ï¼šé«˜å½±å“åŠ›ä½†ä½ä»‹æ•°ä¸­å¿ƒæ€§
            if popularity > 0 and betweenness >= 0:
                popularity_norm = popularity / max_popularity
                anomaly_score = popularity_norm / (betweenness + 1e-6)
            else:
                anomaly_score = 0
            
            anomaly_scores.append({
                'user_id': user_id,
                'popularity': popularity,
                'betweenness': betweenness,
                'anomaly_score': anomaly_score
            })
        
        anomaly_df = pd.DataFrame(anomaly_scores)
        anomaly_df = anomaly_df.sort_values('anomaly_score', ascending=False)
        
        n_to_exclude = int(np.ceil(len(anomaly_df) * exclude_pct / 100))
        abnormal_users = set(anomaly_df.head(n_to_exclude)['user_id'])
        
        print(f"æ£€æµ‹åˆ° {len(abnormal_users)} ä¸ªç»“æ„æ´å¼‚å¸¸ç”¨æˆ·")
        
        # æ˜¾ç¤ºå‰5ä¸ªå¼‚å¸¸ç”¨æˆ·ç¤ºä¾‹
        if len(abnormal_users) > 0:
            print("å‰5ä¸ªç»“æ„æ´å¼‚å¸¸ç”¨æˆ·ç¤ºä¾‹:")
            top_5 = anomaly_df.head(5)
            for idx, (_, row) in enumerate(top_5.iterrows()):
                print(f"  {idx+1}. ç”¨æˆ·ID: {row['user_id']}, å¼‚å¸¸åˆ†æ•°: {row['anomaly_score']:.2f}, "
                      f"å½±å“åŠ›: {row['popularity']:.2f}, ä»‹æ•°ä¸­å¿ƒæ€§: {row['betweenness']:.6f}")
        
        return abnormal_users
    
    def method3_neighbor_quality_anomaly(self, exclude_pct):
        """æ–¹æ³•3: é‚»å±…è´¨é‡å¼‚å¸¸æ£€æµ‹ - ä¿®æ­£ç‰ˆï¼Œç¡®ä¿ç²¾ç¡®æ’é™¤æ¯”ä¾‹"""
        print(f"\n=== æ–¹æ³•3: é‚»å±…è´¨é‡å¼‚å¸¸æ£€æµ‹ (æ’é™¤å‰{exclude_pct}%) ===")
        
        if exclude_pct == 0:
            print("åŸå§‹ç½‘ç»œï¼Œæ— éœ€æ£€æµ‹å¼‚å¸¸ç”¨æˆ·")
            return set()
        
        print("æ­£åœ¨è®¡ç®—é‚»å±…è´¨é‡å¼‚å¸¸åˆ†æ•°...")
        anomaly_scores = []
        processed_count = 0
        
        for _, row in self.merged_df.iterrows():
            user_id = row['user_id']
            popularity = row['avg_popularity']
            
            processed_count += 1
            if processed_count % 1000 == 0:
                print(f"å·²å¤„ç† {processed_count}/{len(self.merged_df)} ä¸ªç”¨æˆ·...")
            
            # è·å–ç”¨æˆ·çš„å‡ºé‚»å±…ï¼ˆå…³æ³¨çš„äººï¼‰
            neighbors = self.user_neighbors.get(user_id, set())
            
            # è®¡ç®—é‚»å±…çš„å½±å“åŠ›
            if len(neighbors) > 0:
                neighbor_popularities = []
                for neighbor in neighbors:
                    neighbor_pop = self.popularity_map.get(neighbor, 0)
                    neighbor_popularities.append(neighbor_pop)
                
                avg_neighbor_popularity = np.mean(neighbor_popularities)
                
                # å¼‚å¸¸åˆ†æ•°ï¼šè‡ªèº«å½±å“åŠ›/é‚»å±…å¹³å‡å½±å“åŠ›
                # æ¯”å€¼è¶Šå¤§ï¼Œè¯´æ˜è‡ªå·±å½±å“åŠ›é«˜ä½†é‚»å±…å½±å“åŠ›ä½ï¼Œè¶Šå¼‚å¸¸
                if avg_neighbor_popularity > 0:
                    anomaly_score = popularity / avg_neighbor_popularity
                else:
                    anomaly_score = popularity  # å¦‚æœé‚»å±…å½±å“åŠ›éƒ½æ˜¯0ï¼Œåˆ™å¼‚å¸¸åˆ†æ•°å°±æ˜¯è‡ªèº«å½±å“åŠ›
            else:
                # æ²¡æœ‰é‚»å±…çš„ç”¨æˆ·ï¼Œå¼‚å¸¸åˆ†æ•°è®¾ä¸ºè‡ªèº«å½±å“åŠ›
                anomaly_score = popularity
            
            anomaly_scores.append({
                'user_id': user_id,
                'popularity': popularity,
                'neighbor_count': len(neighbors),
                'avg_neighbor_popularity': np.mean([self.popularity_map.get(n, 0) for n in neighbors]) if neighbors else 0,
                'anomaly_score': anomaly_score
            })
        
        # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
        anomaly_df = pd.DataFrame(anomaly_scores)
        anomaly_df = anomaly_df.sort_values('anomaly_score', ascending=False)
        
        # æŒ‰ç…§æŒ‡å®šæ¯”ä¾‹æ’é™¤ç”¨æˆ· - åŸºäºæ€»ç”¨æˆ·æ•°è®¡ç®—
        n_to_exclude = int(np.ceil(len(self.merged_df) * exclude_pct / 100))
        abnormal_users = set(anomaly_df.head(n_to_exclude)['user_id'])
        
        actual_exclude_pct = len(abnormal_users) / len(self.merged_df) * 100
        
        print(f"æ£€æµ‹åˆ° {len(abnormal_users)} ä¸ªé‚»å±…è´¨é‡å¼‚å¸¸ç”¨æˆ·")
        print(f"å®é™…æ’é™¤æ¯”ä¾‹: {actual_exclude_pct:.2f}%")
        
        # æ˜¾ç¤ºå‰5ä¸ªå¼‚å¸¸ç”¨æˆ·ç¤ºä¾‹
        if len(abnormal_users) > 0:
            print("å‰5ä¸ªé‚»å±…è´¨é‡å¼‚å¸¸ç”¨æˆ·ç¤ºä¾‹:")
            top_5 = anomaly_df.head(5)
            for idx, (_, row) in enumerate(top_5.iterrows()):
                print(f"  {idx+1}. ç”¨æˆ·ID: {row['user_id']}, å¼‚å¸¸åˆ†æ•°: {row['anomaly_score']:.2f}, "
                    f"å½±å“åŠ›: {row['popularity']:.2f}, é‚»å±…æ•°: {row['neighbor_count']}, "
                    f"é‚»å±…å¹³å‡å½±å“åŠ›: {row['avg_neighbor_popularity']:.2f}")
        
        return abnormal_users
    
    def method4_celebrity_removal(self):
        """ğŸ”¥ æ–°å¢æ–¹æ³•4: æ˜æ˜Ÿç”¨æˆ·ç§»é™¤æ£€æµ‹ - ç›´æ¥ç§»é™¤æ‰€æœ‰æ˜æ˜Ÿç”¨æˆ·"""
        print(f"\n=== æ–¹æ³•4: æ˜æ˜Ÿç”¨æˆ·ç§»é™¤æ£€æµ‹ ===")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†åˆ—
        if 'is_celebrity' not in self.merged_df.columns:
            print("âŒ æ•°æ®ä¸­ç¼ºå°‘is_celebrityåˆ—ï¼Œæ–¹æ³•4æ— æ³•ä½¿ç”¨")
            return set()
        
        print("æ­£åœ¨è¯†åˆ«æ˜æ˜Ÿç”¨æˆ·...")
        
        # æ‰¾å‡ºæ‰€æœ‰æ˜æ˜Ÿç”¨æˆ·
        celebrity_users = set(self.merged_df[self.merged_df['is_celebrity'] == True]['user_id'])
        
        actual_exclude_pct = len(celebrity_users) / len(self.merged_df) * 100
        
        print(f"æ£€æµ‹åˆ° {len(celebrity_users)} ä¸ªæ˜æ˜Ÿç”¨æˆ·")
        print(f"å®é™…æ’é™¤æ¯”ä¾‹: {actual_exclude_pct:.2f}%")
        
        # æ˜¾ç¤ºå‰5ä¸ªæ˜æ˜Ÿç”¨æˆ·ç¤ºä¾‹
        if len(celebrity_users) > 0:
            celebrity_df = self.merged_df[self.merged_df['is_celebrity'] == True].sort_values('avg_popularity', ascending=False)
            print("å‰5ä¸ªæ˜æ˜Ÿç”¨æˆ·ç¤ºä¾‹ï¼ˆæŒ‰å½±å“åŠ›æ’åºï¼‰:")
            top_5 = celebrity_df.head(5)
            for idx, (_, row) in enumerate(top_5.iterrows()):
                # è·å–ç”¨æˆ·çš„åº¦æ•°ä¿¡æ¯
                out_degree = row.get('global_out_degree', 0)
                in_degree = row.get('global_in_degree', 0)
                print(f"  {idx+1}. ç”¨æˆ·ID: {row['user_id']}, å½±å“åŠ›: {row['avg_popularity']:.2f}, "
                      f"å‡ºåº¦: {out_degree}, å…¥åº¦: {in_degree}")
        
        return celebrity_users
    
    def detect_anomalies_batch(self, methods, exclude_percentages):
        """æ‰¹é‡æ£€æµ‹å¤šä¸ªæ¯”ä¾‹ä¸‹çš„å¼‚å¸¸ç”¨æˆ·"""
        all_results = {}
        
        for exclude_pct in exclude_percentages:
            print(f"\n{'='*80}")
            print(f"å¼€å§‹å¤„ç†æ’é™¤æ¯”ä¾‹: {exclude_pct}%")
            print(f"{'='*80}")
            
            all_abnormal_users = set()
            method_results = {}
            
            if 1 in methods:
                method1_users = self.method1_influence_edge_ratio(exclude_pct)
                all_abnormal_users.update(method1_users)
                method_results['method1'] = method1_users
            
            if 2 in methods:
                method2_users = self.method2_structural_hole_anomaly(exclude_pct)
                all_abnormal_users.update(method2_users)
                method_results['method2'] = method2_users
            
            if 3 in methods:
                method3_users = self.method3_neighbor_quality_anomaly(exclude_pct)
                all_abnormal_users.update(method3_users)
                method_results['method3'] = method3_users
            
            # ğŸ”¥ æ–°å¢ï¼šæ–¹æ³•4çš„å¤„ç†
            if 4 in methods:
                method4_users = self.method4_celebrity_removal()
                all_abnormal_users.update(method4_users)
                method_results['method4'] = method4_users
            
            all_results[exclude_pct] = {
                'all_abnormal_users': all_abnormal_users,
                'method_results': method_results
            }
            
            print(f"\næ’é™¤æ¯”ä¾‹ {exclude_pct}% å¤„ç†å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(all_abnormal_users)} ä¸ªå¼‚å¸¸ç”¨æˆ·")
        
        return all_results

def interactive_detection():
    """äº¤äº’å¼å¼‚å¸¸æ£€æµ‹"""
    print("=== é«˜çº§å¼‚å¸¸ç”¨æˆ·æ£€æµ‹ç³»ç»Ÿï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰===")
    print("\nå¯ç”¨çš„æ£€æµ‹æ–¹æ³•ï¼š")
    print("1. å½±å“åŠ›/è¿è¾¹æ•°æ¯”å€¼å¼‚å¸¸æ£€æµ‹")
    print("2. ç»“æ„æ´å¼‚å¸¸æ£€æµ‹ï¼ˆé«˜å½±å“åŠ›ä½†ä½ä»‹æ•°ä¸­å¿ƒæ€§ï¼‰")
    print("3. é‚»å±…è´¨é‡å¼‚å¸¸æ£€æµ‹ï¼ˆé«˜å½±å“åŠ›ä½†é‚»å±…è´¨é‡ä½ï¼‰")
    print("4. æ˜æ˜Ÿç”¨æˆ·ç§»é™¤æ£€æµ‹ï¼ˆç›´æ¥ç§»é™¤æ‰€æœ‰æ˜æ˜Ÿç”¨æˆ·ï¼‰ğŸ”¥æ–°å¢")
    
    # é€‰æ‹©æ–¹æ³•
    while True:
        try:
            method_input = input("\nè¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ–¹æ³•ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚1,2,3,4ï¼‰: ").strip()
            methods = [int(x.strip()) for x in method_input.split(',')]
            if all(m in [1, 2, 3, 4] for m in methods):
                break
            else:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ–¹æ³•ç¼–å·ï¼ˆ1-4ï¼‰")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    # ğŸ”¥ æ–°å¢ï¼šå¦‚æœé€‰æ‹©äº†æ–¹æ³•4ï¼Œæé†’ç”¨æˆ·å…¶ç‰¹æ®Šæ€§
    if 4 in methods:
        print(f"\nâš ï¸ æ³¨æ„ï¼šæ–¹æ³•4ï¼ˆæ˜æ˜Ÿç”¨æˆ·ç§»é™¤ï¼‰ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼š")
        print(f"   - ä¸ä¾èµ–æ’é™¤æ¯”ä¾‹ï¼Œç›´æ¥ç§»é™¤æ‰€æœ‰æ˜æ˜Ÿç”¨æˆ·")
        print(f"   - å°†åœ¨æ¯ä¸ªæ’é™¤æ¯”ä¾‹ä¸‹éƒ½æ‰§è¡Œç›¸åŒçš„æ˜æ˜Ÿç”¨æˆ·ç§»é™¤")
        confirm = input("ç¡®è®¤è¦åŒ…å«æ–¹æ³•4å—ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            methods.remove(4)
            print(f"âœ… å·²ç§»é™¤æ–¹æ³•4ï¼Œå½“å‰é€‰æ‹©ï¼š{methods}")
    
    # é€‰æ‹©æ’é™¤æ¯”ä¾‹
    while True:
        try:
            percentages_input = input("è¯·è¾“å…¥è¦æµ‹è¯•çš„æ’é™¤ç™¾åˆ†æ¯”ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œå¦‚0,1,3,5,10ï¼Œå…¶ä¸­0è¡¨ç¤ºåŸå§‹ç½‘ç»œï¼‰: ").strip()
            exclude_percentages = [float(x.strip()) for x in percentages_input.split(',')]
            if all(0 <= p <= 50 for p in exclude_percentages):
                # å»é‡å¹¶æ’åº
                exclude_percentages = sorted(list(set(exclude_percentages)))
                break
            else:
                print("è¯·è¾“å…¥0-50ä¹‹é—´çš„ç™¾åˆ†æ¯”")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    return methods, exclude_percentages

def save_batch_results(detector, all_results, methods, output_base_dir):
    """ä¿å­˜æ‰¹é‡æ£€æµ‹ç»“æœ"""
    method_names = '_'.join([f"method{m}" for m in methods])
    
    # ä¸ºæ¯ä¸ªæ’é™¤æ¯”ä¾‹åˆ›å»ºæ–‡ä»¶å¤¹å¹¶ä¿å­˜ç»“æœ
    for exclude_pct, results in all_results.items():
        if exclude_pct == 0:
            # åŸå§‹ç½‘ç»œç‰¹æ®Šå¤„ç†
            output_dir = f'{output_base_dir}/original_network_0pct'
        else:
            output_dir = f'{output_base_dir}/advanced_{method_names}_{exclude_pct}pct'
        
        ensure_dir(output_dir)
        
        all_abnormal_users = results['all_abnormal_users']
        method_results = results['method_results']
        
        # ä¿å­˜ç®€å•çš„å¼‚å¸¸ç”¨æˆ·åˆ—è¡¨
        if exclude_pct == 0:
            # åŸå§‹ç½‘ç»œï¼šåˆ›å»ºç©ºçš„DataFrame
            abnormal_df = pd.DataFrame(columns=['user_id', 'detection_method', 'exclude_percentage'])
        else:
            abnormal_df = pd.DataFrame({
                'user_id': list(all_abnormal_users),
                'detection_method': f"methods_{method_names}",
                'exclude_percentage': exclude_pct
            })
        
        # ğŸ”¥ ä¿®æ”¹ï¼šæ·»åŠ è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†
        detailed_info = []
        if exclude_pct == 0:
            # åŸå§‹ç½‘ç»œï¼šç©ºè¯¦ç»†ä¿¡æ¯
            detailed_df = pd.DataFrame(columns=['user_id', 'avg_popularity', 'edge_count', 
                                               'detected_by_method1', 'detected_by_method2', 
                                               'detected_by_method3', 'detected_by_method4', 'is_celebrity'])
        else:
            # è®¡ç®—edge_countç”¨äºè¯¦ç»†ä¿¡æ¯
            user_out_edges = detector.edges_df['source'].value_counts().to_dict()
            user_in_edges = detector.edges_df['target'].value_counts().to_dict()
            
            for user_id in all_abnormal_users:
                user_info = detector.merged_df[detector.merged_df['user_id'] == user_id].iloc[0]
                out_count = user_out_edges.get(user_id, 0)
                in_count = user_in_edges.get(user_id, 0)
                total_edges = out_count + in_count
                
                detailed_info.append({
                    'user_id': user_id,
                    'avg_popularity': user_info['avg_popularity'],
                    'edge_count': total_edges,
                    'detected_by_method1': user_id in method_results.get('method1', set()),
                    'detected_by_method2': user_id in method_results.get('method2', set()),
                    'detected_by_method3': user_id in method_results.get('method3', set()),
                    'detected_by_method4': user_id in method_results.get('method4', set()),  # ğŸ”¥æ–°å¢
                    'is_celebrity': user_info.get('is_celebrity', False)  # ğŸ”¥æ–°å¢
                })
            detailed_df = pd.DataFrame(detailed_info)
        
        # ä¿å­˜æ–‡ä»¶
        abnormal_df.to_csv(f'{output_dir}/abnormal_users.csv', index=False)
        detailed_df.to_csv(f'{output_dir}/abnormal_users_detailed.csv', index=False)
        
        # ğŸ”¥ ä¿®æ”¹ï¼šç”ŸæˆæŠ¥å‘Šï¼ŒåŒ…å«æ–¹æ³•4ä¿¡æ¯
        with open(f'{output_dir}/detection_report.txt', 'w', encoding='utf-8') as f:
            if exclude_pct == 0:
                f.write("=== åŸå§‹ç½‘ç»œåˆ†ææŠ¥å‘Š ===\n\n")
                f.write(f"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ç½‘ç»œç±»å‹: åŸå§‹ç½‘ç»œï¼ˆæœªæ’é™¤ä»»ä½•ç”¨æˆ·ï¼‰\n")
                f.write(f"æ’é™¤æ¯”ä¾‹: {exclude_pct}%\n\n")
            else:
                f.write("=== é«˜çº§å¼‚å¸¸ç”¨æˆ·æ£€æµ‹æŠ¥å‘Š ===\n\n")
                f.write(f"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ä½¿ç”¨æ–¹æ³•: {methods}\n")
                f.write(f"æ’é™¤æ¯”ä¾‹: {exclude_pct}%\n\n")
            
            f.write(f"æ€»ç”¨æˆ·æ•°: {len(detector.merged_df)}\n")
            f.write(f"æ£€æµ‹åˆ°çš„å¼‚å¸¸ç”¨æˆ·æ€»æ•°: {len(all_abnormal_users)}\n")
            f.write(f"å®é™…æ’é™¤æ¯”ä¾‹: {len(all_abnormal_users)/len(detector.merged_df)*100:.2f}%\n\n")
            
            if exclude_pct > 0:
                for method_name, users in method_results.items():
                    method_descriptions = {
                        'method1': 'å½±å“åŠ›/è¿è¾¹æ•°æ¯”å€¼å¼‚å¸¸',
                        'method2': 'ç»“æ„æ´å¼‚å¸¸ï¼ˆé«˜å½±å“åŠ›ä½ä»‹æ•°ä¸­å¿ƒæ€§ï¼‰',
                        'method3': 'é‚»å±…è´¨é‡å¼‚å¸¸ï¼ˆé«˜å½±å“åŠ›ä½é‚»å±…è´¨é‡ï¼‰',
                        'method4': 'æ˜æ˜Ÿç”¨æˆ·ç§»é™¤'  # ğŸ”¥æ–°å¢
                    }
                    desc = method_descriptions.get(method_name, method_name)
                    f.write(f"{method_name} ({desc}) æ£€æµ‹åˆ°: {len(users)} ä¸ªç”¨æˆ·\n")
                
                # æ–¹æ³•é‡å åˆ†æ
                if len(method_results) > 1:
                    f.write(f"\n=== æ–¹æ³•é‡å åˆ†æ ===\n")
                    method_sets = list(method_results.values())
                    if len(method_sets) >= 2:
                        intersection = set.intersection(*method_sets)
                        f.write(f"æ‰€æœ‰æ–¹æ³•å…±åŒæ£€æµ‹åˆ°: {len(intersection)} ä¸ªç”¨æˆ·\n")
                        
                        # ğŸ”¥ æ–°å¢ï¼šç‰¹åˆ«åˆ†ææ–¹æ³•4çš„é‡å æƒ…å†µ
                        if 'method4' in method_results:
                            method4_users = method_results['method4']
                            other_methods = {k: v for k, v in method_results.items() if k != 'method4'}
                            if other_methods:
                                other_union = set.union(*other_methods.values()) if other_methods else set()
                                overlap_with_others = method4_users.intersection(other_union)
                                f.write(f"æ˜æ˜Ÿç”¨æˆ·ä¸å…¶ä»–æ–¹æ³•é‡å : {len(overlap_with_others)} ä¸ªç”¨æˆ·\n")
                                f.write(f"ä»…è¢«æ–¹æ³•4æ£€æµ‹åˆ°çš„æ˜æ˜Ÿç”¨æˆ·: {len(method4_users - other_union)} ä¸ªç”¨æˆ·\n")
        
        print(f"  - æ’é™¤æ¯”ä¾‹ {exclude_pct}% ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

def main():
    """ä¸»å‡½æ•°"""
    # äº¤äº’å¼é€‰æ‹©
    methods, exclude_percentages = interactive_detection()
    
    print(f"\nå°†è¦æ‰§è¡Œçš„é…ç½®:")
    print(f"æ£€æµ‹æ–¹æ³•: {methods}")
    print(f"æ’é™¤æ¯”ä¾‹: {exclude_percentages}")
    print(f"æ€»å…±éœ€è¦å¤„ç† {len(exclude_percentages)} ç§æƒ…å†µ")
    
    # ğŸ”¥ æ–°å¢ï¼šç‰¹åˆ«æé†’æ–¹æ³•4çš„ç‰¹æ®Šæ€§
    if 4 in methods:
        print(f"\nâš ï¸ ç‰¹åˆ«æé†’ï¼šæ–¹æ³•4ï¼ˆæ˜æ˜Ÿç”¨æˆ·ç§»é™¤ï¼‰å°†åœ¨æ¯ä¸ªæ¯”ä¾‹ä¸‹æ‰§è¡Œç›¸åŒæ“ä½œ")
    
    confirm = input("\nç¡®è®¤å¼€å§‹æ‰¹é‡æ£€æµ‹ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆæ£€æµ‹")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = AdvancedAnomalyDetector()
    if not detector.load_data():
        return
    
    # æ‰§è¡Œæ‰¹é‡æ£€æµ‹
    print(f"\nå¼€å§‹æ‰§è¡Œæ‰¹é‡å¼‚å¸¸æ£€æµ‹...")
    start_time = datetime.now()
    
    all_results = detector.detect_anomalies_batch(methods, exclude_percentages)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_base_dir = 'results/pick_out_abnormal_users'
    ensure_dir(output_base_dir)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    print(f"\nå¼€å§‹ä¿å­˜æ‰¹é‡æ£€æµ‹ç»“æœ...")
    save_batch_results(detector, all_results, methods, output_base_dir)
    
    # ğŸ”¥ ä¿®æ”¹ï¼šç”Ÿæˆæ‰¹é‡æ±‡æ€»æŠ¥å‘Šï¼ŒåŒ…å«æ–¹æ³•4ä¿¡æ¯
    summary_path = f'{output_base_dir}/batch_detection_summary.txt'
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("====== æ‰¹é‡å¼‚å¸¸ç”¨æˆ·æ£€æµ‹æ±‡æ€»æŠ¥å‘Š ======\n")
        f.write(f"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ä½¿ç”¨æ–¹æ³•: {methods}\n")
        f.write(f"æµ‹è¯•æ¯”ä¾‹: {exclude_percentages}\n\n")
        
        # ğŸ”¥ æ–°å¢ï¼šæ–¹æ³•è¯´æ˜
        f.write("=== æ£€æµ‹æ–¹æ³•è¯´æ˜ ===\n")
        method_descriptions = {
            1: "å½±å“åŠ›/è¿è¾¹æ•°æ¯”å€¼å¼‚å¸¸æ£€æµ‹",
            2: "ç»“æ„æ´å¼‚å¸¸æ£€æµ‹ï¼ˆé«˜å½±å“åŠ›ä½†ä½ä»‹æ•°ä¸­å¿ƒæ€§ï¼‰",
            3: "é‚»å±…è´¨é‡å¼‚å¸¸æ£€æµ‹ï¼ˆé«˜å½±å“åŠ›ä½†é‚»å±…è´¨é‡ä½ï¼‰",
            4: "æ˜æ˜Ÿç”¨æˆ·ç§»é™¤æ£€æµ‹ï¼ˆç›´æ¥ç§»é™¤æ‰€æœ‰æ˜æ˜Ÿç”¨æˆ·ï¼‰"
        }
        for method_num in methods:
            f.write(f"æ–¹æ³•{method_num}: {method_descriptions[method_num]}\n")
        f.write("\n")
        
        f.write("=== å„æ¯”ä¾‹æ£€æµ‹ç»“æœæ±‡æ€» ===\n")
        f.write(f"{'æ’é™¤æ¯”ä¾‹':<10} {'å¼‚å¸¸ç”¨æˆ·æ•°':<12} {'å®é™…æ’é™¤æ¯”ä¾‹':<15} {'çŠ¶æ€'}\n")
        f.write("-" * 50 + "\n")
        
        for exclude_pct in exclude_percentages:
            results = all_results[exclude_pct]
            abnormal_count = len(results['all_abnormal_users'])
            actual_pct = abnormal_count / len(detector.merged_df) * 100
            status = "åŸå§‹ç½‘ç»œ" if exclude_pct == 0 else "å·²å¤„ç†"
            
            f.write(f"{exclude_pct}%{'':<7} {abnormal_count:<12} {actual_pct:<15.2f}% {status}\n")
        
        f.write(f"\n=== å¤„ç†ç»Ÿè®¡ ===\n")
        f.write(f"æ€»ç”¨æˆ·æ•°: {len(detector.merged_df)}\n")
        f.write(f"å¤„ç†çš„æ¯”ä¾‹æ•°: {len(exclude_percentages)}\n")
        f.write(f"ä½¿ç”¨çš„æ£€æµ‹æ–¹æ³•æ•°: {len(methods)}\n")
        
        # ğŸ”¥ æ–°å¢ï¼šæ˜æ˜Ÿç”¨æˆ·ç»Ÿè®¡
        if 4 in methods and 'is_celebrity' in detector.merged_df.columns:
            celebrity_count = detector.merged_df['is_celebrity'].sum()
            f.write(f"æ˜æ˜Ÿç”¨æˆ·æ€»æ•°: {celebrity_count}\n")
            f.write(f"æ˜æ˜Ÿç”¨æˆ·æ¯”ä¾‹: {celebrity_count/len(detector.merged_df)*100:.2f}%\n")
    
    end_time = datetime.now()
    duration = end_time - start_time
    
    print(f"\n{'='*80}")
    print(f"æ‰¹é‡æ£€æµ‹å®Œæˆï¼")
    print(f"æ€»è€—æ—¶: {duration}")
    print(f"å¤„ç†äº† {len(exclude_percentages)} ç§æ’é™¤æ¯”ä¾‹: {exclude_percentages}")
    print(f"ç»“æœä¿å­˜åœ¨: {output_base_dir}")
    print(f"æ‰¹é‡æ±‡æ€»æŠ¥å‘Š: {summary_path}")
    
    # æ‰“å°ç®€è¦ç»“æœ
    print(f"\n=== æ‰¹é‡æ£€æµ‹ç»“æœé¢„è§ˆ ===")
    for exclude_pct in exclude_percentages:
        results = all_results[exclude_pct]
        abnormal_count = len(results['all_abnormal_users'])
        actual_pct = abnormal_count / len(detector.merged_df) * 100
        status = "ï¼ˆåŸå§‹ç½‘ç»œï¼‰" if exclude_pct == 0 else ""
        print(f"{exclude_pct}% æ’é™¤: {abnormal_count} ä¸ªå¼‚å¸¸ç”¨æˆ· ({actual_pct:.2f}%) {status}")

if __name__ == "__main__":
    main()