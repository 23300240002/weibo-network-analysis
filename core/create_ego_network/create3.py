# 3.3 - å…¼å®¹æ–°fetché˜¶æ®µè¾“å‡º
import os
import json
import pandas as pd
import numpy as np
import easygraph as eg
import easygraph.functions as eg_f
from scipy import linalg
from datetime import datetime
from collections import defaultdict, deque
import signal
import sys

def normalize_id(id_value):
    """è§„èŒƒåŒ–ç”¨æˆ·IDï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´"""
    try:
        id_str = str(id_value).strip()
        if id_str == '-2147483648':
            return id_str
        return str(int(float(id_str)))
    except:
        return str(id_value).strip()

def signal_handler(signum, frame):
    """å¤„ç†Ctrl+Cä¿¡å·"""
    print(f"\n\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)")
    print(f"ğŸ“ æ­£åœ¨ä¿å­˜å½“å‰è¿›åº¦...")
    sys.exit(0)

def load_celebrity_users(base_dir):
    """åŠ è½½æ˜æ˜Ÿç”¨æˆ·åˆ—è¡¨"""
    high_fans_file = os.path.join(base_dir, 'high_fans_users.csv')
    
    if not os.path.exists(high_fans_file):
        print(f"âš ï¸ æœªæ‰¾åˆ°æ˜æ˜Ÿç”¨æˆ·æ–‡ä»¶: {high_fans_file}")
        print(f"   æ‰€æœ‰ç”¨æˆ·çš„is_celebrityå°†è®¾ä¸ºFalse")
        return set()
    
    try:
        high_fans_df = pd.read_csv(high_fans_file)
        celebrity_users = set(high_fans_df['user_id'].apply(normalize_id))
        print(f"âœ… æˆåŠŸåŠ è½½ {len(celebrity_users)} ä¸ªæ˜æ˜Ÿç”¨æˆ·")
        return celebrity_users
    except Exception as e:
        print(f"âŒ åŠ è½½æ˜æ˜Ÿç”¨æˆ·æ–‡ä»¶å¤±è´¥: {e}")
        print(f"   æ‰€æœ‰ç”¨æˆ·çš„is_celebrityå°†è®¾ä¸ºFalse")
        return set()

def load_user_categories(base_dir):
    """ğŸ”¥ æ–°å¢ï¼šåŠ è½½ç”¨æˆ·ç±»åˆ«ä¿¡æ¯ï¼ˆA/B/Cï¼‰"""
    users_file = os.path.join(base_dir, 'users.csv')
    
    if not os.path.exists(users_file):
        print(f"âš ï¸ æœªæ‰¾åˆ°ç”¨æˆ·æ–‡ä»¶: {users_file}")
        print(f"   æ‰€æœ‰ç”¨æˆ·çš„categoryå°†è®¾ä¸ºUnknown")
        return {}
    
    try:
        users_df = pd.read_csv(users_file)
        users_df['user_id'] = users_df['user_id'].apply(normalize_id)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰categoryåˆ—
        if 'category' not in users_df.columns:
            print(f"âš ï¸ users.csvä¸­æœªæ‰¾åˆ°categoryåˆ—")
            print(f"   æ‰€æœ‰ç”¨æˆ·çš„categoryå°†è®¾ä¸ºUnknown")
            return {}
        
        user_categories = dict(zip(users_df['user_id'], users_df['category']))
        
        # ç»Ÿè®¡å„ç±»ç”¨æˆ·æ•°é‡
        category_counts = users_df['category'].value_counts()
        print(f"âœ… æˆåŠŸåŠ è½½ç”¨æˆ·ç±»åˆ«ä¿¡æ¯:")
        for category, count in category_counts.items():
            print(f"   - {category}ç±»ç”¨æˆ·: {count} ä¸ª")
        
        return user_categories
    except Exception as e:
        print(f"âŒ åŠ è½½ç”¨æˆ·ç±»åˆ«æ–‡ä»¶å¤±è´¥: {e}")
        print(f"   æ‰€æœ‰ç”¨æˆ·çš„categoryå°†è®¾ä¸ºUnknown")
        return {}

def get_user_selected_metrics():
    """äº¤äº’å¼é€‰æ‹©è¦è®¡ç®—çš„ç½‘ç»œæŒ‡æ ‡"""
    print("\n" + "="*60)
    print("è¯·é€‰æ‹©è¦è®¡ç®—çš„ç½‘ç»œæŒ‡æ ‡ï¼š")
    print("="*60)
    print("1. å¯†åº¦ (Density)")
    print("2. èšç±»ç³»æ•° (Clustering Coefficient)")  
    print("3. é‚»å±…å¹³å‡åº¦ (Average Nearest Neighbor Degree)")
    print("4. ä»‹æ•°ä¸­å¿ƒæ€§ (Betweenness Centrality) - è®¡ç®—è¾ƒæ…¢")
    print("5. è°±åŠå¾„ (Spectral Radius)")
    print("6. æ¨¡å—åº¦ (Modularity)")
    print("="*60)
    print("è¾“å…¥ç¤ºä¾‹ï¼š")
    print("  - è®¡ç®—å‰ä¸‰ä¸ªæŒ‡æ ‡ï¼š1 2 3")
    print("  - è®¡ç®—äº”å¤§æŒ‡æ ‡ï¼ˆæ¨èï¼‰ï¼š1 2 3 5 6") 
    print("  - è®¡ç®—å…¨éƒ¨å…­å¤§æŒ‡æ ‡ï¼š1 2 3 4 5 6")
    print("  - å¿«é€Ÿæ¨¡å¼ï¼ˆå‰ä¸‰ä¸ªï¼‰ï¼š1 2 3")
    
    while True:
        try:
            user_input = input("\nè¯·è¾“å…¥æŒ‡æ ‡åºå·ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰: ").strip()
            if not user_input:
                print("âŒ è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                continue
                
            selected_numbers = [int(x.strip()) for x in user_input.split()]
            
            # éªŒè¯è¾“å…¥èŒƒå›´
            if not all(1 <= num <= 6 for num in selected_numbers):
                print("âŒ è¯·è¾“å…¥1-6ä¹‹é—´çš„æ•°å­—")
                continue
                
            # å»é‡å¹¶æ’åº
            selected_numbers = sorted(list(set(selected_numbers)))
            
            # æ˜¾ç¤ºé€‰æ‹©çš„æŒ‡æ ‡
            metric_names = {
                1: "å¯†åº¦",
                2: "èšç±»ç³»æ•°", 
                3: "é‚»å±…å¹³å‡åº¦",
                4: "ä»‹æ•°ä¸­å¿ƒæ€§",
                5: "è°±åŠå¾„",
                6: "æ¨¡å—åº¦"
            }
            
            print(f"\nâœ… å·²é€‰æ‹© {len(selected_numbers)} ä¸ªæŒ‡æ ‡ï¼š")
            for num in selected_numbers:
                print(f"   {num}. {metric_names[num]}")
            
            # ç‰¹åˆ«æé†’ä»‹æ•°ä¸­å¿ƒæ€§çš„è®¡ç®—æ—¶é—´
            if 4 in selected_numbers:
                print(f"\nâš ï¸ æ³¨æ„ï¼šä»‹æ•°ä¸­å¿ƒæ€§è®¡ç®—è¾ƒæ…¢ï¼Œå¤§ç½‘ç»œå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´")
                confirm = input("ç¡®è®¤è¦åŒ…å«ä»‹æ•°ä¸­å¿ƒæ€§å—ï¼Ÿ(y/n): ").strip().lower()
                if confirm != 'y':
                    selected_numbers.remove(4)
                    print(f"âœ… å·²ç§»é™¤ä»‹æ•°ä¸­å¿ƒæ€§ï¼Œå½“å‰é€‰æ‹©ï¼š{selected_numbers}")
            
            return selected_numbers
            
        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”")
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return []

def load_existing_progress(metrics_output, ego_networks_output):
    """åŠ è½½å·²æœ‰è¿›åº¦ï¼Œè¿”å›å·²å®Œæˆçš„ç”¨æˆ·é›†åˆå’Œæ•°æ®"""
    completed_users = set()
    existing_metrics = {}
    existing_ego_info = {}
    
    # åŠ è½½å·²æœ‰çš„ç½‘ç»œæŒ‡æ ‡
    if os.path.exists(metrics_output):
        print(f"æ‰¾åˆ°å·²æœ‰ç½‘ç»œæŒ‡æ ‡æ–‡ä»¶: {metrics_output}")
        with open(metrics_output, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    record = json.loads(line)
                    user_id = record["user_id"]
                    metrics = record["network_metrics"]
                    existing_metrics[user_id] = metrics
                    completed_users.add(user_id)
                except Exception as e:
                    print(f"  - è­¦å‘Šï¼šè§£æç½‘ç»œæŒ‡æ ‡æ–‡ä»¶ä¸­çš„è¡Œæ—¶å‡ºé”™ï¼š{e}")
                    continue
    
    # åŠ è½½å·²æœ‰çš„egoç½‘ç»œä¿¡æ¯
    if os.path.exists(ego_networks_output):
        print(f"æ‰¾åˆ°å·²æœ‰egoç½‘ç»œä¿¡æ¯æ–‡ä»¶: {ego_networks_output}")
        with open(ego_networks_output, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    record = json.loads(line)
                    user_id = record["user_id"]
                    ego_info = record["ego_network_info"]
                    existing_ego_info[user_id] = ego_info
                except Exception as e:
                    print(f"  - è­¦å‘Šï¼šè§£æegoç½‘ç»œä¿¡æ¯æ–‡ä»¶ä¸­çš„è¡Œæ—¶å‡ºé”™ï¼š{e}")
                    continue
    
    print(f"å·²åŠ è½½ {len(completed_users)} ä¸ªå·²å®Œæˆç”¨æˆ·çš„æ•°æ®")
    return completed_users, existing_metrics, existing_ego_info

def append_to_jsonl(data, file_path, is_metrics=True):
    """è¿½åŠ æ•°æ®åˆ°JSONLæ–‡ä»¶"""
    with open(file_path, 'a', encoding='utf-8') as f:
        if is_metrics:
            for user_id, metrics in data.items():
                record = {"user_id": user_id, "network_metrics": metrics}
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
        else:
            for user_id, ego_info in data.items():
                record = {"user_id": user_id, "ego_network_info": ego_info}
                f.write(json.dumps(record, ensure_ascii=False) + "\n")

def ego_graph_fixed(G, n, radius=1, center=True, undirected=False, distance=None):
    """ä¿®å¤ç‰ˆçš„ego_graphå‡½æ•°ï¼ŒçœŸæ­£æ”¯æŒåŒå‘è¾¹"""
    
    if distance is not None:
        # å¦‚æœæŒ‡å®šäº†è·ç¦»æƒé‡ï¼Œä½¿ç”¨dijkstraç®—æ³•
        if undirected and G.is_directed():
            # å¯¹æœ‰å‘å›¾æ‰§è¡ŒåŒå‘æœç´¢
            sp_out = eg_f.single_source_dijkstra(G, n, weight=distance)
            # åå‘å›¾æœç´¢å…¥è¾¹
            G_reversed = G.reverse()
            sp_in = eg_f.single_source_dijkstra(G_reversed, n, weight=distance)
            # åˆå¹¶ç»“æœ
            sp = {}
            for node, dist in sp_out.items():
                if dist <= radius:
                    sp[node] = dist
            for node, dist in sp_in.items():
                if dist <= radius:
                    if node not in sp or dist < sp[node]:
                        sp[node] = dist
        else:
            sp = eg_f.single_source_dijkstra(G, n, weight=distance)
    else:
        # ä½¿ç”¨BFSè¿›è¡ŒåŒå‘æœç´¢
        if undirected and G.is_directed():
            sp = bidirectional_bfs(G, n, radius)
        else:
            sp = eg_f.single_source_dijkstra(G, n)
    
    # è¿‡æ»¤è·ç¦»èŒƒå›´å†…çš„èŠ‚ç‚¹
    nodes = [node for node, dist in sp.items() if dist <= radius]
    
    # åˆ›å»ºå­å›¾
    H = G.nodes_subgraph(nodes)
    
    if not center:
        H.remove_node(n)
    
    return H

def bidirectional_bfs(G, start_node, radius):
    """åŒå‘BFSï¼šåŒæ—¶æ²¿å…¥è¾¹å’Œå‡ºè¾¹æ‰©å±•"""
    distances = {start_node: 0}
    current_level = {start_node}
    
    for level in range(1, radius + 1):
        next_level = set()
        
        for node in current_level:
            # å‡ºè¾¹é‚»å±…ï¼ˆnodeå…³æ³¨çš„äººï¼‰
            for successor in G.successors(node):
                if successor not in distances:
                    distances[successor] = level
                    next_level.add(successor)
            
            # å…¥è¾¹é‚»å±…ï¼ˆå…³æ³¨nodeçš„äººï¼‰
            for predecessor in G.predecessors(node):
                if predecessor not in distances:
                    distances[predecessor] = level
                    next_level.add(predecessor)
        
        current_level = next_level
        if not current_level:
            break
    
    return distances

def calculate_global_degrees(G, center_node):
    """è®¡ç®—ç”¨æˆ·åœ¨å…¨å›¾ä¸­çš„å‡ºåº¦å’Œå…¥åº¦"""
    try:
        # å‡ºåº¦ï¼šè¯¥ç”¨æˆ·æŒ‡å‘å¤šå°‘å…¶ä»–ç”¨æˆ·
        out_degree = G.out_degree(center_node) if G.has_node(center_node) else 0
        
        # å…¥åº¦ï¼šå¤šå°‘å…¶ä»–ç”¨æˆ·æŒ‡å‘è¯¥ç”¨æˆ·
        in_degree = G.in_degree(center_node) if G.has_node(center_node) else 0
        
        # æ€»åº¦æ•°
        total_degree = out_degree + in_degree
        
        return out_degree, in_degree, total_degree
    except Exception as e:
        print(f"    âš ï¸ è®¡ç®—å…¨å›¾åº¦æ•°å¤±è´¥: {e}")
        return 0, 0, 0

def calculate_spectral_radius(G):
    """è®¡ç®—å›¾çš„è°±åŠå¾„ï¼ˆæœ€å¤§ç‰¹å¾å€¼çš„ç»å¯¹å€¼ï¼‰"""
    adj_matrix = eg.to_numpy_array(G)
    eigenvalues = linalg.eigvals(adj_matrix)
    return float(np.max(np.abs(eigenvalues)))

def calculate_modularity(G):
    """è®¡ç®—å›¾çš„æ¨¡å—åº¦"""
    partition, modularity_value = louvain_communities_fixed(G, threshold=0.001)
    return modularity_value

def calculate_betweenness_centrality(G, center_node):
    """è®¡ç®—ä»‹æ•°ä¸­å¿ƒæ€§ï¼Œæ­£ç¡®å¤„ç†EasyGraphè¿”å›çš„ç»“æœ"""
    bc_start = datetime.now()
    bc = eg_f.betweenness_centrality(G)
    
    # å¤„ç†EasyGraphå¯èƒ½è¿”å›åˆ—è¡¨æˆ–å­—å…¸çš„æƒ…å†µ
    if isinstance(bc, list):
        # å¦‚æœè¿”å›åˆ—è¡¨ï¼Œéœ€è¦æ‰¾åˆ°ä¸­å¿ƒèŠ‚ç‚¹çš„ç´¢å¼•
        node_list = list(G.nodes)
        if center_node in node_list:
            center_index = node_list.index(center_node)
            result = bc[center_index] if center_index < len(bc) else 0.0
        else:
            result = 0.0
    elif isinstance(bc, dict):
        # å¦‚æœè¿”å›å­—å…¸ï¼Œç›´æ¥è·å–
        result = bc.get(center_node, 0.0)
    else:
        # å…¶ä»–æƒ…å†µï¼Œè¿”å›0
        result = 0.0
    
    bc_time = datetime.now() - bc_start
    return result, bc_time

def louvain_communities_fixed(G, weight="weight", threshold=0.001, max_iterations=100, max_levels=10):
    """ä¿®å¤ç‰ˆçš„Louvainç¤¾åŒºæ£€æµ‹ç®—æ³•"""
    partition = [{u} for u in G.nodes]
    m = G.size(weight="weight")
    is_directed = G.is_directed()
    
    initial_mod = modularity_fixed(G, partition)
    
    level = 1
    partition, inner_partition, improvement = _one_level_fixed(G, m, partition, is_directed)
    
    new_mod = modularity_fixed(G, partition)
    mod_gain = new_mod - initial_mod
    
    while improvement and level < max_levels:
        level += 1
        
        G_new = G.__class__()
        node2com = {}
        
        for i, part in enumerate(partition):
            G_new.add_node(i)
            for node in part:
                node2com[node] = i
        
        for edge in G.edges:
            u, v, data = edge
            if u in node2com and v in node2com:
                com1 = node2com[u]
                com2 = node2com[v]
                edge_weight = data.get(weight, 1)
                
                if G_new.has_edge(com1, com2):
                    G_new[com1][com2][weight] += edge_weight
                else:
                    G_new.add_edge(com1, com2, **{weight: edge_weight})
        
        G = G_new
        partition = [{u} for u in G.nodes]
        partition, inner_partition, improvement = _one_level_fixed(G, m, partition, is_directed)
        
        if improvement:
            cur_mod = modularity_fixed(G, partition)
            mod_gain = cur_mod - new_mod
            
            if mod_gain <= threshold:
                break
            new_mod = cur_mod
    
    return partition, new_mod

def _one_level_fixed(G, m, partition, is_directed=False, max_iterations=100):
    """ä¿®å¤ç‰ˆçš„_one_levelå‡½æ•°"""
    node2com = {u: i for i, u in enumerate(G.nodes)}
    inner_partition = [{u} for u in G.nodes]
    
    degrees = dict(G.degree(weight="weight"))
    Stot = []
    for i in range(len(partition)):
        Stot.append(sum(degrees.get(node, 0) for node in partition[i]))
    
    nbrs = {u: {v: data.get("weight", 1) for v, data in G[u].items() if v != u} for u in G}
    rand_nodes = list(G.nodes)
    
    nb_moves = 1
    iteration = 0
    total_moves = 0
    recent_moves = []
    oscillation_threshold = 3
    
    while nb_moves > 0 and iteration < max_iterations:
        iteration += 1
        nb_moves = 0
        
        for u in rand_nodes:
            best_mod = 0
            best_com = node2com[u]
            
            weights2com = defaultdict(float)
            for nbr, wt in nbrs.get(u, {}).items():
                weights2com[node2com[nbr]] += wt
            
            degree = degrees.get(u, 0)
            if best_com < len(Stot):
                Stot[best_com] -= degree
                remove_cost = -weights2com.get(best_com, 0) / m + (Stot[best_com] * degree) / (2 * m**2)
            else:
                remove_cost = 0
            
            for nbr_com, wt in weights2com.items():
                if nbr_com < len(Stot):
                    gain = remove_cost + wt / m - (Stot[nbr_com] * degree) / (2 * m**2)
                    if gain > best_mod:
                        best_mod = gain
                        best_com = nbr_com
            
            if best_com < len(Stot):
                Stot[best_com] += degree
            
            if best_com != node2com[u]:
                com = G.nodes[u].get("nodes", {u})
                if not isinstance(com, set):
                    com = {com}
                
                partition[node2com[u]].difference_update(com)
                inner_partition[node2com[u]].remove(u)
                
                if best_com < len(partition):
                    partition[best_com].update(com)
                    inner_partition[best_com].add(u)
                
                nb_moves += 1
                total_moves += 1
                node2com[u] = best_com
        
        old_partition = partition.copy()
        partition = list(filter(len, partition))
        inner_partition = list(filter(len, inner_partition))
        
        if len(old_partition) != len(partition):
            new_node2com = {}
            for i, community in enumerate(partition):
                for node in community:
                    new_node2com[node] = i
            node2com = new_node2com
            
            new_Stot = []
            for i in range(len(partition)):
                new_Stot.append(sum(degrees.get(node, 0) for node in partition[i]))
            Stot = new_Stot
        
        recent_moves.append(nb_moves)
        if len(recent_moves) > oscillation_threshold:
            recent_moves.pop(0)
            if len(set(recent_moves)) == 1 and recent_moves[0] > 0:
                break
    
    return partition, inner_partition, total_moves > 0

def modularity_fixed(G, communities, weight="weight"):
    """è®¡ç®—ç»™å®šç¤¾åŒºåˆ’åˆ†çš„æ¨¡å—åº¦"""
    if not isinstance(communities, list):
        communities = list(communities)

    directed = G.is_directed()
    m = G.size(weight=weight)
    if m == 0:
        return 0
        
    if directed:
        out_degree = dict(G.out_degree(weight=weight))
        in_degree = dict(G.in_degree(weight=weight))
        norm = 1 / m
    else:
        out_degree = dict(G.degree(weight=weight))
        in_degree = out_degree
        norm = 1 / (2 * m)
    
    def val(u, v):
        try:
            w = G[u][v].get(weight, 1)
        except KeyError:
            w = 0
        if u == v and not directed:
            w *= 2
        return w - in_degree.get(u, 0) * out_degree.get(v, 0) * norm
    
    Q = 0
    for c in communities:
        for u in c:
            for v in c:
                Q += val(u, v)
    
    Q = Q * norm
    
    print(f"  - ç¤¾åŒºæ•°é‡: {len(communities)}")
    print(f"  - æœ€ç»ˆæ¨¡å—åº¦: {Q:.6f}")
    
    return Q

def calculate_average_neighbor_degree(G, node):
    """è®¡ç®—èŠ‚ç‚¹çš„é‚»å±…å¹³å‡åº¦æ•°"""
    neighbors = list(G.neighbors(node))
    if not neighbors:
        return 0.0
    
    neighbor_degrees = []
    for neighbor in neighbors:
        deg_val = len(list(G.neighbors(neighbor)))
        neighbor_degrees.append(deg_val)
    
    return sum(neighbor_degrees) / len(neighbor_degrees)

def create_ego_network_fixed(G, node, radius=2):
    """ä½¿ç”¨ä¿®å¤ç‰ˆego_graphåˆ›å»ºçœŸæ­£çš„åŒå‘äºŒè·³é‚»å±…ç½‘ç»œ"""
    print(f"  - å¼€å§‹åˆ›å»ºçœŸæ­£çš„åŒå‘äºŒè·³é‚»å±…ç½‘ç»œ...")
    
    # ä½¿ç”¨ä¿®å¤ç‰ˆçš„ego_graphå‡½æ•°ï¼Œè®¾ç½®undirected=Trueä»¥è·å–åŒå‘è¾¹
    ego_graph = ego_graph_fixed(G, node, radius=radius, center=True, undirected=True)
    
    if ego_graph:
        print(f"  - åŒå‘ego_graphåˆ›å»ºæˆåŠŸ: {ego_graph.number_of_nodes()} èŠ‚ç‚¹, {ego_graph.number_of_edges()} è¾¹")
        
        # éªŒè¯ä¸­å¿ƒèŠ‚ç‚¹çš„é‚»å±…æƒ…å†µ
        if node in ego_graph:
            # å¯¹äºæœ‰å‘å›¾ï¼Œè®¡ç®—å…¥é‚»å±…å’Œå‡ºé‚»å±…
            if G.is_directed():
                in_neighbors = []
                out_neighbors = []
                
                # åœ¨åŸå›¾ä¸­æŸ¥æ‰¾ä¸­å¿ƒèŠ‚ç‚¹çš„çœŸå®é‚»å±…
                for u in G.nodes:
                    if G.has_edge(u, node):  # uæŒ‡å‘nodeï¼ˆå…¥é‚»å±…ï¼‰
                        in_neighbors.append(u)
                    if G.has_edge(node, u):  # nodeæŒ‡å‘uï¼ˆå‡ºé‚»å±…ï¼‰
                        out_neighbors.append(u)
                
                # è¿‡æ»¤ï¼šåªç»Ÿè®¡åœ¨ego_graphä¸­çš„é‚»å±…
                in_neighbors_in_ego = [n for n in in_neighbors if n in ego_graph]
                out_neighbors_in_ego = [n for n in out_neighbors if n in ego_graph]
                
                print(f"  - ä¸­å¿ƒèŠ‚ç‚¹ {node}: å…¥é‚»å±…(ç²‰ä¸) {len(in_neighbors_in_ego)} ä¸ª, å‡ºé‚»å±…(å…³æ³¨) {len(out_neighbors_in_ego)} ä¸ª")
            else:
                neighbors = list(ego_graph.neighbors(node))
                print(f"  - ä¸­å¿ƒèŠ‚ç‚¹ {node}: é‚»å±… {len(neighbors)} ä¸ª")
    
    return ego_graph

def calculate_network_metrics_selected(ego_graph, center_node, selected_metrics, global_graph, celebrity_users, user_categories):
    """ğŸ”¥ ä¿®æ”¹ç‰ˆï¼šè®¡ç®—ç½‘ç»œæŒ‡æ ‡ï¼ŒåŒ…å«å…¨å›¾åº¦æ•°ã€æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†å’Œç”¨æˆ·ç±»åˆ«"""
    metrics = {}
    
    # åŸºæœ¬ç½‘ç»œä¿¡æ¯
    metrics['node_count'] = ego_graph.number_of_nodes()
    metrics['edge_count'] = ego_graph.number_of_edges()
    metrics['center_node'] = center_node
    
    # è®¡ç®—ç”¨æˆ·åœ¨å…¨å›¾ä¸­çš„åº¦æ•°ä¿¡æ¯
    global_out_degree, global_in_degree, global_total_degree = calculate_global_degrees(global_graph, center_node)
    metrics['global_out_degree'] = global_out_degree
    metrics['global_in_degree'] = global_in_degree
    metrics['global_total_degree'] = global_total_degree
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºæ˜æ˜Ÿç”¨æˆ·
    is_celebrity = center_node in celebrity_users
    metrics['is_celebrity'] = is_celebrity
    
    # ğŸ”¥ æ–°å¢ï¼šè·å–ç”¨æˆ·ç±»åˆ«ä¿¡æ¯
    user_category = user_categories.get(center_node, 'Unknown')
    metrics['user_category'] = user_category
    
    print(f"  - å…¨å›¾åº¦æ•°ä¿¡æ¯: å‡ºåº¦ {global_out_degree}, å…¥åº¦ {global_in_degree}, æ€»åº¦æ•° {global_total_degree}")
    print(f"  - æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†: {'æ˜¯' if is_celebrity else 'å¦'}")
    print(f"  - ç”¨æˆ·ç±»åˆ«: {user_category}")
    
    # æ ¹æ®é€‰æ‹©è®¡ç®—æŒ‡æ ‡
    for metric_num in selected_metrics:
        start_time = datetime.now()
        try:
            if metric_num == 1:  # å¯†åº¦
                value = eg.density(ego_graph)
                metrics['density'] = value
                elapsed = datetime.now() - start_time
                print(f"  - density è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {elapsed}")
                
            elif metric_num == 2:  # èšç±»ç³»æ•°
                value = eg_f.clustering(ego_graph, center_node)
                metrics['clustering_coefficient'] = value
                elapsed = datetime.now() - start_time
                print(f"  - clustering_coefficient è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {elapsed}")
                
            elif metric_num == 3:  # é‚»å±…å¹³å‡åº¦
                value = calculate_average_neighbor_degree(ego_graph, center_node)
                metrics['average_nearest_neighbor_degree'] = value
                elapsed = datetime.now() - start_time
                print(f"  - average_nearest_neighbor_degree è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {elapsed}")
                
            elif metric_num == 4:  # ä»‹æ•°ä¸­å¿ƒæ€§
                value, bc_time = calculate_betweenness_centrality(ego_graph, center_node)
                metrics['betweenness_centrality'] = value
                print(f"  - betweenness_centrality è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {bc_time}")
                
            elif metric_num == 5:  # è°±åŠå¾„
                value = calculate_spectral_radius(ego_graph)
                metrics['spectral_radius'] = value
                elapsed = datetime.now() - start_time
                print(f"  - spectral_radius è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {elapsed}")
                
            elif metric_num == 6:  # æ¨¡å—åº¦
                value = calculate_modularity(ego_graph)
                metrics['modularity'] = value
                elapsed = datetime.now() - start_time
                print(f"  - modularity è®¡ç®—å®Œæˆ: {value:.6f}, è€—æ—¶: {elapsed}")
                
        except Exception as e:
            metric_names = {1: 'density', 2: 'clustering_coefficient', 3: 'average_nearest_neighbor_degree',
                          4: 'betweenness_centrality', 5: 'spectral_radius', 6: 'modularity'}
            metric_name = metric_names.get(metric_num, f'metric_{metric_num}')
            print(f"  - âŒ {metric_name} è®¡ç®—å¤±è´¥: {e}")
            metrics[metric_name] = 0.0
    
    return metrics

def save_all_metrics_to_jsonl(all_metrics_data, output_path):
    """å°†æ‰€æœ‰ç½‘ç»œæŒ‡æ ‡ä¿å­˜åˆ°JSONLæ–‡ä»¶ï¼ˆå®Œæ•´é‡å†™ï¼‰"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for user_id, metrics in all_metrics_data.items():
            record = {"user_id": user_id, "network_metrics": metrics}
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    print(f"æ‰€æœ‰ç½‘ç»œæŒ‡æ ‡æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

def save_all_ego_networks_info(all_ego_networks_info, output_path):
    """å°†æ‰€æœ‰äºŒè·³é‚»å±…ç½‘ç»œä¿¡æ¯ä¿å­˜åˆ°JSONLæ–‡ä»¶ï¼ˆå®Œæ•´é‡å†™ï¼‰"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for user_id, info in all_ego_networks_info.items():
            record = {"user_id": user_id, "ego_network_info": info}
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    print(f"æ‰€æœ‰äºŒè·³é‚»å±…ç½‘ç»œä¿¡æ¯å·²ä¿å­˜åˆ°: {output_path}")

def metrics_to_dataframe(metrics_data):
    """å°†æŒ‡æ ‡æ•°æ®è½¬æ¢ä¸ºDataFrameæ ¼å¼"""
    records = []
    for user_id, metrics in metrics_data.items():
        record = {"user_id": user_id}
        record.update(metrics)
        records.append(record)
    return pd.DataFrame(records)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨ï¼Œä¼˜é›…å¤„ç†Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    
    start_time = datetime.now()
    print(f"å¼€å§‹åˆ†ææ—¶é—´: {start_time}")
    print("ä½¿ç”¨ä¿®å¤ç‰ˆEasyGraph ego_graphï¼ŒçœŸæ­£æ”¯æŒåŒå‘è¾¹")
    print("æ”¯æŒäº¤äº’å¼é€‰æ‹©ç½‘ç»œæŒ‡æ ‡")
    print("æ”¯æŒæ–­ç‚¹ç»­ä¼ åŠŸèƒ½")
    print("ğŸ”¥ å·²ä¿®å¤ä»‹æ•°ä¸­å¿ƒæ€§è®¡ç®—å’ŒCtrl+Cå¤„ç†")
    print("ğŸ”¥ æ–°å¢å…¨å›¾åº¦æ•°ä¿¡æ¯ï¼šå‡ºåº¦ã€å…¥åº¦ã€æ€»åº¦æ•°")
    print("ğŸ”¥ æ–°å¢æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†ï¼šåŸºäºhigh_fans_users.csv")
    print("ğŸ”¥ æ–°å¢ç”¨æˆ·ç±»åˆ«ä¿¡æ¯ï¼šA/B/Cç±»æ ‡è¯†")
    print("ğŸ”¥ æ–°å¢åŒé‡å½±å“åŠ›æŒ‡æ ‡ï¼šæ”¯æŒavg_popularity_of_all")
    
    try:
        # äº¤äº’å¼é€‰æ‹©æŒ‡æ ‡
        selected_metrics = get_user_selected_metrics()
        if not selected_metrics:
            print("âŒ æœªé€‰æ‹©ä»»ä½•æŒ‡æ ‡ï¼Œç¨‹åºé€€å‡º")
            return
        
        # æ˜¾ç¤ºæœ€ç»ˆé€‰æ‹©
        metric_names = {
            1: "å¯†åº¦", 2: "èšç±»ç³»æ•°", 3: "é‚»å±…å¹³å‡åº¦",
            4: "ä»‹æ•°ä¸­å¿ƒæ€§", 5: "è°±åŠå¾„", 6: "æ¨¡å—åº¦"
        }
        print(f"\nâœ… å°†è®¡ç®—ä»¥ä¸‹ {len(selected_metrics)} ä¸ªæŒ‡æ ‡:")
        for num in selected_metrics:
            print(f"   - {metric_names[num]}")
        print(f"âœ… åŒæ—¶è®°å½•ï¼šå‡ºåº¦ã€å…¥åº¦ã€æ€»åº¦æ•°ã€äºŒè·³ç½‘ç»œèŠ‚ç‚¹æ•°ã€äºŒè·³ç½‘ç»œè¾¹æ•°ã€æ˜¯å¦æ˜æ˜Ÿç”¨æˆ·ã€ç”¨æˆ·ç±»åˆ«")
        
        # è®¾ç½®è·¯å¾„
        base_dir = 'C:/Tengfei/data/data/domain_network3/user_3855570307'
        edges_path = os.path.join(base_dir, 'edges.csv')
        popularity_path = os.path.join(base_dir, 'popularity.csv')
        output_dir = f'C:/Tengfei/data/results/user_3855570307_metrics'
        metrics_output = os.path.join(output_dir, 'network_metrics.jsonl')
        ego_networks_output = os.path.join(output_dir, 'ego_networks_info.jsonl')
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(edges_path):
            print(f"âŒ æœªæ‰¾åˆ°edges.csvæ–‡ä»¶: {edges_path}")
            return
        
        if not os.path.exists(popularity_path):
            print(f"âŒ æœªæ‰¾åˆ°popularity.csvæ–‡ä»¶: {popularity_path}")
            return
        
        # åŠ è½½æ˜æ˜Ÿç”¨æˆ·åˆ—è¡¨
        celebrity_users = load_celebrity_users(base_dir)
        
        # ğŸ”¥ æ–°å¢ï¼šåŠ è½½ç”¨æˆ·ç±»åˆ«ä¿¡æ¯
        user_categories = load_user_categories(base_dir)
        
        print("æ­£åœ¨åŠ è½½ç½‘ç»œæ•°æ®...")
        edges_df = pd.read_csv(edges_path)
        popularity_df = pd.read_csv(popularity_path)
        
        # é¢„å¤„ç†ï¼šè§„èŒƒåŒ–ID
        print("æ­£åœ¨è§„èŒƒåŒ–ç”¨æˆ·ID...")
        edges_df['source'] = edges_df['source'].apply(normalize_id)
        edges_df['target'] = edges_df['target'].apply(normalize_id)
        popularity_df['user_id'] = popularity_df['user_id'].apply(normalize_id)
        
        # ğŸ”¥ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰avg_popularity_of_allåˆ—
        has_total_popularity = 'avg_popularity_of_all' in popularity_df.columns
        if has_total_popularity:
            print(f"âœ… æ£€æµ‹åˆ°æ€»ä½“å½±å“åŠ›åˆ— (avg_popularity_of_all)")
            non_zero_total = (popularity_df['avg_popularity_of_all'] > 0).sum()
            print(f"   æœ‰ {non_zero_total} ä¸ªç”¨æˆ·å…·æœ‰éé›¶æ€»ä½“å½±å“åŠ›")
        else:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°æ€»ä½“å½±å“åŠ›åˆ—ï¼Œè¯·å…ˆè¿è¡Œfetch3_helper.py")
        
        # æ„å»ºæœ‰å‘å›¾
        print("æ­£åœ¨æ„å»ºç½‘ç»œ...")
        G = eg.DiGraph()
        edge_count = 0
        for _, row in edges_df.iterrows():
            source = str(row['source'])
            target = str(row['target'])
            G.add_edge(source, target)
            edge_count += 1
            if edge_count % 10000 == 0:
                print(f"å·²åŠ è½½ {edge_count} æ¡è¾¹")
        
        print(f"ç½‘ç»œæ„å»ºå®Œæˆï¼ŒåŒ…å« {G.number_of_nodes()} ä¸ªèŠ‚ç‚¹å’Œ {G.number_of_edges()} æ¡è¾¹")
        
        # è·å–éœ€è¦è®¡ç®—çš„ç”¨æˆ·åˆ—è¡¨
        users_to_process = set(popularity_df['user_id'].tolist())
        users_in_graph = set(str(node) for node in G.nodes)
        valid_users = users_to_process.intersection(users_in_graph)
        
        print(f"\n=== ç”¨æˆ·åŒ¹é…ç»Ÿè®¡ ===")
        print(f"Popularityæ–‡ä»¶ä¸­ç”¨æˆ·æ€»æ•°: {len(users_to_process)}")
        print(f"å›¾ä¸­èŠ‚ç‚¹æ€»æ•°: {len(G.nodes)}")
        print(f"æœ‰æ•ˆåŒ¹é…ç”¨æˆ·æ•°: {len(valid_users)}")
        print(f"åŒ¹é…ç‡: {len(valid_users)/len(users_to_process)*100:.2f}%")
        print(f"æ˜æ˜Ÿç”¨æˆ·æ€»æ•°: {len(celebrity_users)}")
        print(f"ç”¨æˆ·ç±»åˆ«ä¿¡æ¯æ€»æ•°: {len(user_categories)}")
        
        # æ£€æŸ¥æ–­ç‚¹ç»­ä¼ 
        has_existing_files = os.path.exists(metrics_output) or os.path.exists(ego_networks_output)
        
        if has_existing_files:
            print(f"\nå‘ç°å·²æœ‰çš„è¿›åº¦æ–‡ä»¶ï¼Œé€‰æ‹©è¿è¡Œæ¨¡å¼:")
            print(f"1. æ–­ç‚¹ç»­ä¼ ï¼ˆæ¨èï¼‰")
            print(f"2. é‡æ–°å¼€å§‹")
            
            while True:
                choice = input("è¯·é€‰æ‹© (1/2): ").strip()
                if choice in ['1', '2']:
                    break
                print("è¯·è¾“å…¥æœ‰æ•ˆé€‰é¡¹ (1/2)")
            
            resume_mode = (choice == '1')
        else:
            resume_mode = False
        
        # åˆå§‹åŒ–æ•°æ®
        all_metrics_data = {}
        all_ego_networks_info = {}
        
        if resume_mode:
            print(f"\n=== æ–­ç‚¹ç»­ä¼ æ¨¡å¼ ===")
            completed_users, existing_metrics, existing_ego_info = load_existing_progress(metrics_output, ego_networks_output)
            
            remaining_users = valid_users - completed_users
            print(f"æ€»ç”¨æˆ·æ•°: {len(valid_users)}")
            print(f"å·²å®Œæˆç”¨æˆ·æ•°: {len(completed_users)}")
            print(f"å‰©ä½™ç”¨æˆ·æ•°: {len(remaining_users)}")
            
            if len(remaining_users) == 0:
                print("æ‰€æœ‰ç”¨æˆ·å·²å¤„ç†å®Œæˆ")
                all_metrics_data = existing_metrics
                all_ego_networks_info = existing_ego_info
            else:
                all_metrics_data = existing_metrics.copy()
                all_ego_networks_info = existing_ego_info.copy()
                users_to_calculate = remaining_users
        else:
            print(f"\n=== å…¨æ–°å¼€å§‹æ¨¡å¼ ===")
            if os.path.exists(metrics_output):
                os.remove(metrics_output)
            if os.path.exists(ego_networks_output):
                os.remove(ego_networks_output)
            users_to_calculate = valid_users
        
        # è®¡ç®—ç½‘ç»œæŒ‡æ ‡
        if len(users_to_calculate) > 0:
            processed_count = len(valid_users) - len(users_to_calculate)
            total_users = len(valid_users)
            
            print(f"å¼€å§‹è®¡ç®— {len(users_to_calculate)} ä¸ªç”¨æˆ·çš„ç½‘ç»œæŒ‡æ ‡...")
            batch_metrics = {}
            batch_ego_info = {}
            
            for user_id in users_to_calculate:
                processed_count += 1
                completion = processed_count / total_users * 100
                print(f"\nå¤„ç†ç”¨æˆ· {user_id} (ç¬¬{processed_count}/{total_users}ä¸ª, å®Œæˆ{completion:.1f}%):")
                
                # åˆ›å»ºäºŒè·³é‚»å±…ç½‘ç»œ
                ego_start_time = datetime.now()
                ego_graph = create_ego_network_fixed(G, user_id, radius=2)
                ego_time = datetime.now() - ego_start_time
                
                if ego_graph and ego_graph.number_of_nodes() > 1:
                    print(f"  - åŒå‘äºŒè·³é‚»å±…ç½‘ç»œåˆ›å»ºå®Œæˆï¼Œè€—æ—¶: {ego_time}")
                else:
                    print(f"  - ç½‘ç»œåˆ›å»ºå¤±è´¥æˆ–èŠ‚ç‚¹æ•°è¿‡å°‘ï¼Œè·³è¿‡æ­¤ç”¨æˆ·")
                    continue
                
                # ğŸ”¥ ä¿®æ”¹ï¼šè®¡ç®—ç½‘ç»œæŒ‡æ ‡ï¼Œä¼ å…¥ç”¨æˆ·ç±»åˆ«ä¿¡æ¯
                print(f"  - å¼€å§‹è®¡ç®—é€‰æ‹©çš„ç½‘ç»œæŒ‡æ ‡...")
                metrics_start_time = datetime.now()
                metrics = calculate_network_metrics_selected(ego_graph, user_id, selected_metrics, G, celebrity_users, user_categories)
                metrics_time = datetime.now() - metrics_start_time
                print(f"  - ç½‘ç»œæŒ‡æ ‡è®¡ç®—å®Œæˆ, æ€»è€—æ—¶: {metrics_time}")
                
                # ä¿å­˜æ•°æ®
                batch_metrics[user_id] = metrics
                all_metrics_data[user_id] = metrics
                
                # å­˜å‚¨egoç½‘ç»œä¿¡æ¯ï¼ŒåŒ…å«ç”¨æˆ·ç±»åˆ«
                ego_info = {
                    'node_count': ego_graph.number_of_nodes(),
                    'edge_count': ego_graph.number_of_edges(),
                    'nodes': list(ego_graph.nodes),
                    'selected_metrics': selected_metrics,
                    'global_out_degree': metrics.get('global_out_degree', 0),
                    'global_in_degree': metrics.get('global_in_degree', 0),
                    'global_total_degree': metrics.get('global_total_degree', 0),
                    'is_celebrity': metrics.get('is_celebrity', False),
                    'user_category': metrics.get('user_category', 'Unknown'),  # ğŸ”¥ æ–°å¢
                    'metrics': {k: v for k, v in metrics.items() if k not in ['node_count', 'edge_count', 'center_node', 'global_out_degree', 'global_in_degree', 'global_total_degree', 'is_celebrity', 'user_category']}
                }
                batch_ego_info[user_id] = ego_info
                all_ego_networks_info[user_id] = ego_info
                
                # æ¯10ä¸ªç”¨æˆ·ä¿å­˜ä¸€æ¬¡
                if len(batch_metrics) >= 10:
                    append_to_jsonl(batch_metrics, metrics_output, is_metrics=True)
                    append_to_jsonl(batch_ego_info, ego_networks_output, is_metrics=False)
                    print(f"  - å·²ä¿å­˜ {len(batch_metrics)} ä¸ªç”¨æˆ·çš„ç»“æœ")
                    batch_metrics.clear()
                    batch_ego_info.clear()
            
            # ä¿å­˜å‰©ä½™æ•°æ®
            if batch_metrics:
                append_to_jsonl(batch_metrics, metrics_output, is_metrics=True)
                append_to_jsonl(batch_ego_info, ego_networks_output, is_metrics=False)
        
        # ç”Ÿæˆåˆå¹¶æ•°æ®
        print("æ­£åœ¨ç”Ÿæˆåˆå¹¶æ•°æ®æ–‡ä»¶...")
        metrics_df = metrics_to_dataframe(all_metrics_data)
        
        if len(metrics_df) > 0:
            # ğŸ”¥ ä¿®æ”¹ï¼šåˆå¹¶ä¸¤ç§å½±å“åŠ›æŒ‡æ ‡
            if has_total_popularity:
                # åˆå¹¶ä¸¤ç§å½±å“åŠ›æŒ‡æ ‡
                merged_df = pd.merge(metrics_df, popularity_df[['user_id', 'avg_popularity', 'avg_popularity_of_all']], 
                                    on="user_id", how="inner")
                print(f"âœ… å·²åˆå¹¶ä¸¤ç§å½±å“åŠ›æŒ‡æ ‡: avg_popularity (æœ€æ–°10æ¡) å’Œ avg_popularity_of_all (æ€»ä½“)")
            else:
                # åªæœ‰ä¸€ç§å½±å“åŠ›æŒ‡æ ‡
                merged_df = pd.merge(metrics_df, popularity_df[['user_id', 'avg_popularity']], 
                                    on="user_id", how="inner")
                print(f"âš ï¸ åªæœ‰ä¸€ç§å½±å“åŠ›æŒ‡æ ‡: avg_popularity (æœ€æ–°10æ¡)")
            
            # ä¿å­˜åˆå¹¶æ•°æ®
            merged_output = os.path.join(output_dir, 'merged_metrics_popularity.csv')
            merged_df.to_csv(merged_output, index=False)
            print(f"åˆå¹¶æ•°æ®å·²ä¿å­˜åˆ°: {merged_output}")
            print(f"åŒ…å« {len(merged_df)} è¡Œæ•°æ®")
            
            # æ˜¾ç¤ºè®¡ç®—çš„æŒ‡æ ‡
            calculated_metrics = [col for col in merged_df.columns if col not in ['user_id', 'center_node', 'avg_popularity', 'avg_popularity_of_all']]
            print(f"\nâœ… å·²è®¡ç®—çš„æŒ‡æ ‡å’Œä¿¡æ¯: {calculated_metrics}")
            
            # æ˜¾ç¤ºåº¦æ•°ç»Ÿè®¡
            if 'global_out_degree' in merged_df.columns:
                print(f"\nğŸ“Š åº¦æ•°ç»Ÿè®¡:")
                print(f"   å¹³å‡å‡ºåº¦: {merged_df['global_out_degree'].mean():.2f}")
                print(f"   å¹³å‡å…¥åº¦: {merged_df['global_in_degree'].mean():.2f}")
                print(f"   å¹³å‡æ€»åº¦æ•°: {merged_df['global_total_degree'].mean():.2f}")
            
            # æ˜¾ç¤ºæ˜æ˜Ÿç”¨æˆ·ç»Ÿè®¡
            if 'is_celebrity' in merged_df.columns:
                celebrity_count = merged_df['is_celebrity'].sum()
                print(f"\nğŸŒŸ æ˜æ˜Ÿç”¨æˆ·ç»Ÿè®¡:")
                print(f"   æ˜æ˜Ÿç”¨æˆ·æ•°é‡: {celebrity_count}")
                print(f"   æ˜æ˜Ÿç”¨æˆ·æ¯”ä¾‹: {celebrity_count/len(merged_df)*100:.2f}%")
            
            # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºç”¨æˆ·ç±»åˆ«ç»Ÿè®¡
            if 'user_category' in merged_df.columns:
                category_counts = merged_df['user_category'].value_counts()
                print(f"\nğŸ“‹ ç”¨æˆ·ç±»åˆ«ç»Ÿè®¡:")
                for category, count in category_counts.items():
                    print(f"   {category}ç±»ç”¨æˆ·: {count} ä¸ª ({count/len(merged_df)*100:.1f}%)")
            
            # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºå½±å“åŠ›å¯¹æ¯”ç»Ÿè®¡
            if has_total_popularity:
                print(f"\nğŸ“Š åŒé‡å½±å“åŠ›å¯¹æ¯”:")
                # æœ‰æ•ˆæ•°æ®ï¼ˆéé›¶ï¼‰çš„ç»Ÿè®¡
                valid_recent = merged_df['avg_popularity'] > 0
                valid_total = merged_df['avg_popularity_of_all'] > 0
                
                print(f"   æœ€æ–°10æ¡å½±å“åŠ› > 0: {valid_recent.sum()} ä¸ªç”¨æˆ· ({valid_recent.sum()/len(merged_df)*100:.1f}%)")
                print(f"   æ€»ä½“å½±å“åŠ› > 0: {valid_total.sum()} ä¸ªç”¨æˆ· ({valid_total.sum()/len(merged_df)*100:.1f}%)")
                
                if valid_recent.any():
                    print(f"   æœ€æ–°10æ¡å¹³å‡å€¼: {merged_df.loc[valid_recent, 'avg_popularity'].mean():.2f}")
                if valid_total.any():
                    print(f"   æ€»ä½“å¹³å‡å€¼: {merged_df.loc[valid_total, 'avg_popularity_of_all'].mean():.2f}")
        
        end_time = datetime.now()
        duration = end_time - start_time
        print(f"\næ€»è€—æ—¶: {duration}")
        print(f"ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  - ç½‘ç»œæŒ‡æ ‡: {metrics_output}")
        print(f"  - é‚»å±…ç½‘ç»œä¿¡æ¯: {ego_networks_output}")
        print(f"  - åˆå¹¶æ•°æ®: {merged_output}")
        print(f"\nğŸ”¥ æ–°å¢åŠŸèƒ½å·²å¯ç”¨ï¼š")
        print(f"   âœ… æ¯ä¸ªç”¨æˆ·çš„å‡ºåº¦ã€å…¥åº¦ã€æ€»åº¦æ•°å·²è®°å½•")
        print(f"   âœ… æ¯ä¸ªç”¨æˆ·çš„æ˜æ˜Ÿç”¨æˆ·æ ‡è¯†å·²è®°å½•")
        print(f"   âœ… æ¯ä¸ªç”¨æˆ·çš„ç±»åˆ«ä¿¡æ¯ï¼ˆA/B/Cï¼‰å·²è®°å½•")
        if has_total_popularity:
            print(f"   âœ… åŒé‡å½±å“åŠ›æŒ‡æ ‡ï¼šæœ€æ–°10æ¡ + æ€»ä½“å¹³å‡")
            print(f"   âœ… æ€»è®¡14ä¸ªä¿¡æ¯ï¼šç”¨æˆ·ID + 6å¤§ç½‘ç»œæŒ‡æ ‡ + 7å¤§åŸºç¡€ä¿¡æ¯")
        else:
            print(f"   âš ï¸ å•ä¸€å½±å“åŠ›æŒ‡æ ‡ï¼šä»…æœ€æ–°10æ¡")
            print(f"   âœ… æ€»è®¡13ä¸ªä¿¡æ¯ï¼šç”¨æˆ·ID + 6å¤§ç½‘ç»œæŒ‡æ ‡ + 6å¤§åŸºç¡€ä¿¡æ¯")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
        print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°è¿›åº¦æ–‡ä»¶ï¼Œå¯ä»¥ç¨åç»§ç»­è¿è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‘ç”Ÿå¼‚å¸¸: {e}")
        print(f"ğŸ“ è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œè·¯å¾„é…ç½®")
        sys.exit(1)

if __name__ == "__main__":
    main()