import os
import json
import time
import random
import pandas as pd
import requests
from datetime import datetime
import re

# ğŸ¯ é…ç½®ï¼šä¸fetch3.pyä¿æŒä¸€è‡´çš„å‚æ•°
TARGET_NETWORK_PATH = 'C:/Tengfei/data/data/domain_network3/user_3855570307'
COOKIE_PATH = 'C:/Tengfei/data/crawler/crawler_for_weibo_fans-master/cookie.json'

# é€Ÿåº¦å‚æ•°ï¼ˆä¸fetch3.pyä¿æŒä¸€è‡´ï¼‰
SLEEP_MIN = 0.4
SLEEP_MAX = 0.6
BATCH_INTERVAL_MIN = 0.5
BATCH_INTERVAL_MAX = 1.0

# è¿›åº¦ä¿å­˜å‚æ•°
SAVE_INTERVAL = 20  # æ¯å¤„ç†20ä¸ªç”¨æˆ·ä¿å­˜ä¸€æ¬¡è¿›åº¦
MAX_RETRIES = 3     # æœ€å¤§é‡è¯•æ¬¡æ•°

class WeiboTotalPopularityHelper:
    def __init__(self, cookie_path=COOKIE_PATH):
        self.cookie_path = cookie_path
        self.headers = None
        
    def load_cookies_and_setup_headers(self):
        """åŠ è½½cookieså¹¶è®¾ç½®è¯·æ±‚å¤´"""
        if not os.path.exists(self.cookie_path):
            print(f"âŒ æœªæ‰¾åˆ°cookieæ–‡ä»¶: {self.cookie_path}")
            return False
        
        try:
            with open(self.cookie_path, 'r', encoding='utf-8') as f:
                cookies_list = json.load(f)
            
            # å°†cookiesåˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            cookie_str = '; '.join([f"{cookie['name']}={cookie['value']}" for cookie in cookies_list])
            
            self.headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Cookie': cookie_str,
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Referer': 'https://weibo.com',
            }
            
            print("âœ… Cookieå’Œè¯·æ±‚å¤´è®¾ç½®æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ CookieåŠ è½½å¤±è´¥: {e}")
            return False
    
    def test_login_status(self):
        """æµ‹è¯•ç™»å½•çŠ¶æ€"""
        test_url = 'https://weibo.com/ajax/statuses/mymblog?uid=1234567890&page=1'
        
        try:
            response = requests.get(test_url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if 'ok' in data and data['ok'] == 1:
                    print("âœ… ç™»å½•çŠ¶æ€æ­£å¸¸")
                    return True
                else:
                    print("âš ï¸ ç™»å½•å¯èƒ½æœ‰é—®é¢˜ï¼Œä½†ç»§ç»­å°è¯•")
                    return True
            else:
                print(f"âŒ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ ç™»å½•çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {e}")
            return False
    
    def get_user_profile_info(self, user_id, max_retries=MAX_RETRIES):
        """ğŸ“Š è·å–ç”¨æˆ·èµ„æ–™ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ€»è½¬èµè¯„æ•°å’Œå‘å¸–æ•°ï¼ˆå‚è€ƒfetch_following.pyï¼‰"""
        url = f'https://weibo.com/ajax/profile/info?uid={user_id}'
        
        for retry in range(max_retries):
            try:
                # è®¡ç®—é€€é¿æ—¶é—´
                wait_time = (2 ** retry) * 1 if retry > 0 else 0
                if retry > 0:
                    print(f"    ç¬¬{retry+1}æ¬¡é‡è¯•ï¼Œç­‰å¾…{wait_time}ç§’...")
                    time.sleep(wait_time)
                
                response = requests.get(url, headers=self.headers, timeout=15)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if 'data' in data and 'user' in data['data']:
                        user_info = data['data']['user']
                        
                        # è·å–å‘å¸–æ€»æ•°
                        statuses_count = user_info.get('statuses_count', 0)
                        
                        # è·å–æ€»è½¬èµè¯„æ•°æ®
                        status_counter = user_info.get('status_total_counter', {})
                        
                        if status_counter:
                            # ğŸ”¥ å‚è€ƒfetch_following.pyçš„å¤„ç†æ–¹æ³•
                            reposts_count = int(str(status_counter.get('repost_cnt', '0')).replace(',', ''))
                            attitudes_count = int(str(status_counter.get('like_cnt', '0')).replace(',', ''))
                            comments_count = int(str(status_counter.get('comment_cnt', '0')).replace(',', ''))
                        else:
                            reposts_count = 0
                            attitudes_count = 0
                            comments_count = 0
                        
                        # è®¡ç®—æ€»äº’åŠ¨æ•°
                        total_interactions = reposts_count + attitudes_count + comments_count
                        
                        # è®¡ç®—æ€»ä½“å¹³å‡æµè¡Œåº¦
                        if statuses_count > 0:
                            avg_popularity_of_all = total_interactions / statuses_count
                        else:
                            avg_popularity_of_all = 0.0
                        
                        result = {
                            'statuses_count': statuses_count,
                            'reposts_count': reposts_count,
                            'attitudes_count': attitudes_count,
                            'comments_count': comments_count,
                            'total_interactions': total_interactions,
                            'avg_popularity_of_all': avg_popularity_of_all
                        }
                        
                        return result
                    else:
                        print(f"    âš ï¸ ç”¨æˆ· {user_id} æ•°æ®æ ¼å¼å¼‚å¸¸")
                        return None
                else:
                    print(f"    âš ï¸ ç”¨æˆ· {user_id} è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    
            except Exception as e:
                print(f"    âš ï¸ ç”¨æˆ· {user_id} è¯·æ±‚å¼‚å¸¸: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        print(f"    âŒ ç”¨æˆ· {user_id} è·å–å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
        return None

def load_existing_popularity_data(network_path):
    """åŠ è½½ç°æœ‰çš„popularity.csvæ–‡ä»¶"""
    popularity_file = os.path.join(network_path, 'popularity.csv')
    
    if not os.path.exists(popularity_file):
        print(f"âŒ æœªæ‰¾åˆ°popularity.csvæ–‡ä»¶: {popularity_file}")
        return None
    
    try:
        popularity_df = pd.read_csv(popularity_file)
        print(f"âœ… æˆåŠŸåŠ è½½popularity.csvï¼ŒåŒ…å« {len(popularity_df)} ä¸ªç”¨æˆ·")
        
        # æ£€æŸ¥ç°æœ‰åˆ—
        print(f"ğŸ“‹ ç°æœ‰åˆ—: {list(popularity_df.columns)}")
        
        return popularity_df
        
    except Exception as e:
        print(f"âŒ åŠ è½½popularity.csvå¤±è´¥: {e}")
        return None

def save_progress(processed_data, network_path):
    """ä¿å­˜è¿›åº¦åˆ°ä¸´æ—¶æ–‡ä»¶"""
    progress_file = os.path.join(network_path, 'helper_progress.json')
    
    progress_data = {
        'processed_data': processed_data,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_processed': len(processed_data)
    }
    
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è¿›åº¦å·²ä¿å­˜: {len(processed_data)} ä¸ªç”¨æˆ·å®Œæˆ")

def load_progress(network_path):
    """åŠ è½½è¿›åº¦"""
    progress_file = os.path.join(network_path, 'helper_progress.json')
    
    if not os.path.exists(progress_file):
        return {}
    
    try:
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        processed_data = progress_data.get('processed_data', {})
        timestamp = progress_data.get('timestamp', 'æœªçŸ¥')
        
        print(f"ğŸ“ åŠ è½½è¿›åº¦æ–‡ä»¶: {progress_file}")
        print(f"  ğŸ“Š å·²å¤„ç†ç”¨æˆ·: {len(processed_data)} ä¸ª")
        print(f"  ğŸ“Š ä¿å­˜æ—¶é—´: {timestamp}")
        
        return processed_data
        
    except Exception as e:
        print(f"âŒ åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def update_popularity_csv(original_df, processed_data, network_path):
    """æ›´æ–°popularity.csvæ–‡ä»¶ï¼Œæ·»åŠ avg_popularity_of_allåˆ—"""
    # åˆ›å»ºå¤‡ä»½
    backup_dir = os.path.join(network_path, 'backup')
    os.makedirs(backup_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_file = os.path.join(backup_dir, f'popularity_backup_{timestamp}.csv')
    original_df.to_csv(backup_file, index=False, encoding='utf-8-sig')
    print(f"âœ… åŸå§‹popularity.csvå·²å¤‡ä»½: {backup_file}")
    
    # å¤åˆ¶åŸå§‹æ•°æ®
    updated_df = original_df.copy()
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç»Ÿä¸€æ•°æ®ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œè§£å†³ç±»å‹åŒ¹é…é—®é¢˜
    updated_df['user_id'] = updated_df['user_id'].astype(str)
    
    # æ·»åŠ æ–°åˆ—
    updated_df['avg_popularity_of_all'] = 0.0
    
    # ğŸ”¥ ä¿®å¤ï¼šæ›´æ–°æ•°æ®æ—¶ç¡®ä¿ç±»å‹åŒ¹é…å¹¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
    successful_updates = 0
    failed_updates = 0
    total_updates = len(processed_data)
    
    print(f"\nğŸ”§ å¼€å§‹æ•°æ®æ›´æ–°ï¼Œæ€»è®¡ {total_updates} ä¸ªç”¨æˆ·...")
    
    for user_id, data in processed_data.items():
        # ğŸ”¥ å…³é”®ï¼šç¡®ä¿user_idç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        user_id_str = str(user_id).strip()
        
        # ğŸ”¥ æ–°å¢ï¼šå¤„ç†æµ®ç‚¹æ•°æ ¼å¼ï¼ˆå¦‚"3855570307.0" -> "3855570307"ï¼‰
        if '.' in user_id_str:
            try:
                user_id_str = str(int(float(user_id_str)))
            except:
                pass
        
        mask = updated_df['user_id'] == user_id_str
        
        if mask.any():
            updated_df.loc[mask, 'avg_popularity_of_all'] = data['avg_popularity_of_all']
            successful_updates += 1
        else:
            failed_updates += 1
            if failed_updates <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªå¤±è´¥çš„ä¾‹å­
                print(f"âš ï¸ è­¦å‘Šï¼šç”¨æˆ· {user_id_str} åœ¨DataFrameä¸­æœªæ‰¾åˆ°")
                # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºDataFrameä¸­çš„å®é™…æ ¼å¼
                sample_ids = updated_df['user_id'].head(3).tolist()
                print(f"   DataFrameæ ·æœ¬ID: {sample_ids}")
                print(f"   æŸ¥æ‰¾çš„ID: '{user_id_str}' (ç±»å‹: {type(user_id_str)})")
    
    print(f"\nğŸ”§ æ•°æ®æ›´æ–°ç»“æœ:")
    print(f"  âœ… æˆåŠŸæ›´æ–°: {successful_updates}/{total_updates}")
    print(f"  âŒ æ›´æ–°å¤±è´¥: {failed_updates}/{total_updates}")
    print(f"  ğŸ“Š æˆåŠŸç‡: {successful_updates/total_updates*100:.1f}%")
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    popularity_file = os.path.join(network_path, 'popularity.csv')
    updated_df.to_csv(popularity_file, index=False, encoding='utf-8-sig')
    print(f"âœ… æ›´æ–°åçš„popularity.csvå·²ä¿å­˜: {popularity_file}")
    
    # ğŸ”¥ æ–°å¢ï¼šå¼ºåˆ¶éªŒè¯å†™å…¥ç»“æœ
    print(f"\nğŸ” éªŒè¯å†™å…¥ç»“æœ...")
    verification_df = pd.read_csv(popularity_file)
    non_zero_count = (verification_df['avg_popularity_of_all'] > 0).sum()
    total_count = len(verification_df)
    
    print(f"ğŸ” éªŒè¯ç»“æœ:")
    print(f"  ğŸ“Š æ€»ç”¨æˆ·æ•°: {total_count}")
    print(f"  ğŸ“Š avg_popularity_of_all > 0çš„ç”¨æˆ·æ•°: {non_zero_count}")
    print(f"  ğŸ“Š éé›¶æ¯”ä¾‹: {non_zero_count/total_count*100:.1f}%")
    
    if non_zero_count == 0:
        print(f"âŒ ä¸¥é‡é—®é¢˜ï¼šæ‰€æœ‰ç”¨æˆ·çš„avg_popularity_of_alléƒ½æ˜¯0ï¼")
        print(f"   è¿™è¯´æ˜æ•°æ®æ›´æ–°å®Œå…¨å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç±»å‹åŒ¹é…é—®é¢˜")
        
        # ğŸ”¥ é¢å¤–è°ƒè¯•ï¼šæ£€æŸ¥åŸå§‹æ•°æ®ç±»å‹
        print(f"\nğŸ”§ è°ƒè¯•ä¿¡æ¯:")
        print(f"   åŸå§‹DataFrame user_idç±»å‹: {original_df['user_id'].dtype}")
        print(f"   æ›´æ–°åDataFrame user_idç±»å‹: {updated_df['user_id'].dtype}")
        print(f"   processed_dataæ ·æœ¬keys: {list(processed_data.keys())[:3]}")
    else:
        print(f"âœ… æ•°æ®æ›´æ–°æˆåŠŸï¼")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if non_zero_count > 0:
        print(f"\nğŸ“Š å½±å“åŠ›å¯¹æ¯”ï¼ˆåŸºäºæˆåŠŸæ›´æ–°çš„æ•°æ®ï¼‰:")
        if 'avg_popularity' in updated_df.columns:
            mask_valid = updated_df['avg_popularity_of_all'] > 0
            valid_data = updated_df[mask_valid]
            
            if len(valid_data) > 0:
                print(f"  ğŸ“Š æœ€æ–°10æ¡å¹³å‡å½±å“åŠ›: {valid_data['avg_popularity'].mean():.2f}")
                print(f"  ğŸ“Š æ€»ä½“å¹³å‡å½±å“åŠ›: {valid_data['avg_popularity_of_all'].mean():.2f}")
                
                # ç»Ÿè®¡ä¸º0çš„æƒ…å†µ
                zero_recent = (updated_df['avg_popularity'] == 0).sum()
                zero_total = (updated_df['avg_popularity_of_all'] == 0).sum()
                print(f"  ğŸ“Š æœ€æ–°10æ¡å½±å“åŠ›ä¸º0çš„ç”¨æˆ·: {zero_recent} ä¸ª ({zero_recent/len(updated_df)*100:.1f}%)")
                print(f"  ğŸ“Š æ€»ä½“å½±å“åŠ›ä¸º0çš„ç”¨æˆ·: {zero_total} ä¸ª ({zero_total/len(updated_df)*100:.1f}%)")
    
    # æ¸…ç†è¿›åº¦æ–‡ä»¶
    progress_file = os.path.join(network_path, 'helper_progress.json')
    if os.path.exists(progress_file):
        os.remove(progress_file)
        print(f"âœ… è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")

def main():
    """ä¸»å‡½æ•°"""
    start_time = datetime.now()
    print(f"æ€»ä½“å½±å“åŠ›è¡¥å……å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    print("å¾®åšæ€»ä½“å½±å“åŠ›è¡¥å……å·¥å…· v1.0")
    print(f"ğŸ¯ ç›®æ ‡ç½‘ç»œ: {TARGET_NETWORK_PATH}")
    print(f"ğŸ” ä»»åŠ¡: ä¸ºæ‰€æœ‰ç”¨æˆ·è¡¥å……avg_popularity_of_allï¼ˆæ€»è½¬èµè¯„/æ€»å‘å¸–æ•°ï¼‰")
    print(f"ğŸ“Š æ•°æ®æº: weibo.comç”¨æˆ·èµ„æ–™é¡µ")
    print(f"ğŸ”„ ç‰¹æ€§: æ–­ç‚¹ç»­ä¼ ã€è‡ªåŠ¨å¤‡ä»½ã€è¿›åº¦ä¿å­˜")
    print(f"âš¡ é€Ÿåº¦å‚æ•°: ä¸fetch3.pyä¿æŒä¸€è‡´")
    print("=" * 80)
    
    # æ£€æŸ¥ç›®æ ‡ç½‘ç»œè·¯å¾„
    if not os.path.exists(TARGET_NETWORK_PATH):
        print(f"âŒ ç›®æ ‡ç½‘ç»œè·¯å¾„ä¸å­˜åœ¨: {TARGET_NETWORK_PATH}")
        return False
    
    # åŠ è½½ç°æœ‰popularity.csv
    print(f"\nğŸ” ç¬¬ä¸€æ­¥ï¼šåŠ è½½ç°æœ‰æ•°æ®")
    popularity_df = load_existing_popularity_data(TARGET_NETWORK_PATH)
    
    if popularity_df is None:
        return False
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰avg_popularity_of_allåˆ—
    if 'avg_popularity_of_all' in popularity_df.columns:
        print(f"âš ï¸ å‘ç°å·²å­˜åœ¨avg_popularity_of_allåˆ—")
        overwrite = input("æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®ï¼Ÿ(y/n): ").strip().lower()
        if overwrite != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False
    
    # è·å–ç”¨æˆ·åˆ—è¡¨
    user_list = popularity_df['user_id'].astype(str).tolist()
    print(f"ğŸ“‹ éœ€è¦å¤„ç†çš„ç”¨æˆ·æ€»æ•°: {len(user_list)}")
    
    # åŠ è½½è¿›åº¦
    print(f"\nğŸ”„ ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥è¿›åº¦çŠ¶æ€")
    processed_data = load_progress(TARGET_NETWORK_PATH)
    
    # è®¡ç®—éœ€è¦å¤„ç†çš„ç”¨æˆ·
    users_to_process = [user_id for user_id in user_list if user_id not in processed_data]
    
    print(f"\nğŸ“‹ å¤„ç†è®¡åˆ’:")
    print(f"  ğŸ“Š æ€»ç”¨æˆ·æ•°: {len(user_list)}")
    print(f"  ğŸ“Š å·²å¤„ç†ç”¨æˆ·æ•°: {len(processed_data)}")
    print(f"  ğŸ“Š å¾…å¤„ç†ç”¨æˆ·æ•°: {len(users_to_process)}")
    
    if len(users_to_process) == 0:
        print(f"âœ… æ‰€æœ‰ç”¨æˆ·å·²å¤„ç†å®Œæˆï¼")
        # ç›´æ¥æ›´æ–°CSVæ–‡ä»¶
        update_popularity_csv(popularity_df, processed_data, TARGET_NETWORK_PATH)
        return True
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    print(f"\nâš ï¸ é¢„è®¡éœ€è¦çˆ¬å– {len(users_to_process)} ä¸ªç”¨æˆ·çš„èµ„æ–™ä¿¡æ¯")
    print(f"âš ï¸ æŒ‰å¹³å‡æ¯ç”¨æˆ·3ç§’è®¡ç®—ï¼Œå¤§çº¦éœ€è¦ {len(users_to_process) * 3 / 60:.1f} åˆ†é’Ÿ")
    
    confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return False
    
    # åˆå§‹åŒ–çˆ¬è™«
    print(f"\nğŸš€ ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹çˆ¬å–æ€»ä½“å½±å“åŠ›")
    helper = WeiboTotalPopularityHelper()
    
    if not helper.load_cookies_and_setup_headers():
        print("è¯·å…ˆç¡®ä¿cookieæ–‡ä»¶æœ‰æ•ˆ")
        return False
    
    if not helper.test_login_status():
        print("ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•")
    
    try:
        processed_count = len(processed_data)
        total_users = len(user_list)
        
        print(f"å¼€å§‹å¤„ç†å‰©ä½™çš„ {len(users_to_process)} ä¸ªç”¨æˆ·...")
        
        batch_start_time = datetime.now()
        consecutive_errors = 0
        success_count = 0
        
        for i, user_id in enumerate(users_to_process):
            processed_count += 1
            completion = processed_count / total_users * 100
            
            print(f"\nå¤„ç†ç”¨æˆ· {user_id} [{i+1}/{len(users_to_process)}] (æ€»è¿›åº¦: {completion:.1f}%):")
            
            try:
                # ğŸ”¥ è·å–æ€»ä½“å½±å“åŠ›æ•°æ®
                profile_data = helper.get_user_profile_info(user_id)
                
                if profile_data:
                    processed_data[user_id] = profile_data
                    success_count += 1
                    
                    print(f"  âœ… ç”¨æˆ· {user_id}: å‘å¸–{profile_data['statuses_count']}æ¡, "
                          f"æ€»äº’åŠ¨{profile_data['total_interactions']}, "
                          f"æ€»ä½“å½±å“åŠ›{profile_data['avg_popularity_of_all']:.2f}")
                else:
                    print(f"  âŒ ç”¨æˆ· {user_id}: è·å–å¤±è´¥")
                    # å³ä½¿å¤±è´¥ä¹Ÿè¦è®°å½•ï¼Œé¿å…é‡å¤å°è¯•
                    processed_data[user_id] = {
                        'statuses_count': 0,
                        'reposts_count': 0,
                        'attitudes_count': 0,
                        'comments_count': 0,
                        'total_interactions': 0,
                        'avg_popularity_of_all': 0.0
                    }
                
                # é‡ç½®é”™è¯¯è®¡æ•°
                consecutive_errors = 0
                
                # æ¯å¤„ç†SAVE_INTERVALä¸ªç”¨æˆ·ä¿å­˜ä¸€æ¬¡è¿›åº¦
                if (i + 1) % SAVE_INTERVAL == 0:
                    save_progress(processed_data, TARGET_NETWORK_PATH)
                    
                    # è®¡ç®—é€Ÿåº¦ç»Ÿè®¡
                    batch_duration = datetime.now() - batch_start_time
                    avg_time_per_user = batch_duration.total_seconds() / SAVE_INTERVAL
                    remaining_users = len(users_to_process) - (i + 1)
                    estimated_remaining_time = remaining_users * avg_time_per_user / 60
                    
                    print(f"  ğŸ“Š æ‰¹æ¬¡å®Œæˆ: å¹³å‡æ¯ç”¨æˆ· {avg_time_per_user:.1f} ç§’")
                    print(f"  ğŸ“Š æœ¬æ‰¹æ¬¡æˆåŠŸç‡: {success_count/SAVE_INTERVAL*100:.1f}%")
                    print(f"  ğŸ“Š é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining_time:.1f} åˆ†é’Ÿ")
                    
                    # é‡ç½®æ‰¹æ¬¡è®¡æ—¶å’Œè®¡æ•°
                    batch_start_time = datetime.now()
                    success_count = 0
                
                # éšæœºç­‰å¾…ï¼ˆä¸fetch3.pyä¿æŒä¸€è‡´ï¼‰
                wait_time = random.uniform(SLEEP_MIN, SLEEP_MAX)
                time.sleep(wait_time)
                
            except Exception as e:
                print(f"  âŒ ç”¨æˆ· {user_id} å¤„ç†å¤±è´¥: {e}")
                consecutive_errors += 1
                
                # å¦‚æœè¿ç»­é”™è¯¯è¿‡å¤šï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                if consecutive_errors >= 3:
                    print(f"  âš ï¸ è¿ç»­ {consecutive_errors} ä¸ªé”™è¯¯ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´...")
                    time.sleep(random.uniform(5.0, 10.0))
                
                # è®°å½•å¤±è´¥çš„ç”¨æˆ·
                processed_data[user_id] = {
                    'statuses_count': 0,
                    'reposts_count': 0,
                    'attitudes_count': 0,
                    'comments_count': 0,
                    'total_interactions': 0,
                    'avg_popularity_of_all': 0.0
                }
                
                continue
            
            # æ‰¹æ¬¡é—´ç­‰å¾…
            if i < len(users_to_process) - 1:
                batch_wait = random.uniform(BATCH_INTERVAL_MIN, BATCH_INTERVAL_MAX)
                time.sleep(batch_wait)
        
        # ä¿å­˜æœ€åçš„è¿›åº¦
        save_progress(processed_data, TARGET_NETWORK_PATH)
        
        # æ›´æ–°popularity.csvæ–‡ä»¶
        update_popularity_csv(popularity_df, processed_data, TARGET_NETWORK_PATH)
        
        print(f"\n" + "="*80)
        print(f"æ€»ä½“å½±å“åŠ›è¡¥å……å®Œæˆï¼")
        print(f"="*80)
        print(f"âœ… å¤„ç†ç”¨æˆ·æ•°: {len(user_list)}")
        print(f"âœ… æˆåŠŸç”¨æˆ·æ•°: {len([d for d in processed_data.values() if d['avg_popularity_of_all'] > 0])}")
        print(f"âœ… æ•°æ®å·²æ›´æ–°åˆ°popularity.csv")
        
        print(f"\nğŸ‰ ç°åœ¨popularity.csvåŒ…å«ä¸¤ç§å½±å“åŠ›è¡¡é‡æ–¹æ³•ï¼š")
        print(f"  - avg_popularity: æœ€æ–°10æ¡å¾®åšçš„è½¬èµè¯„å¹³å‡å€¼")
        print(f"  - avg_popularity_of_all: æ€»è½¬èµè¯„æ•°/æ€»å‘å¸–æ•°")
        print(f"  - å¯ä»¥åœ¨ç›¸å…³æ€§åˆ†æä¸­å¯¹æ¯”è¿™ä¸¤ç§æ–¹æ³•çš„æ•ˆæœ")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        # ä¿å­˜å½“å‰è¿›åº¦
        save_progress(processed_data, TARGET_NETWORK_PATH)
        print(f"âœ… å½“å‰è¿›åº¦å·²ä¿å­˜ï¼Œå¯ç¨åç»§ç»­")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        # ä¿å­˜å½“å‰è¿›åº¦
        save_progress(processed_data, TARGET_NETWORK_PATH)
        
    finally:
        pass
    
    end_time = datetime.now()
    duration = end_time - start_time
    print(f"\næ€»è€—æ—¶: {duration}")

if __name__ == "__main__":
    main()